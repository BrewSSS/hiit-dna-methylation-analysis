{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Analysis: Extending the HIIT Methylation Pipeline\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to customize and extend the HIIT methylation analysis pipeline for your specific research needs. We cover advanced customization options that go beyond the default configurations shown in the main pipeline notebooks.\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "1. **Custom Feature Selection**: Adjust stringency parameters and create custom selection criteria\n",
    "2. **Custom Classifiers**: Integrate new machine learning models\n",
    "3. **Extended Enrichment Analysis**: Add custom annotation databases and gene sets\n",
    "4. **Custom Visualizations**: Create publication-ready figures with custom styling\n",
    "5. **Pipeline Extensions**: Integrate external tools and analyses\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This notebook assumes familiarity with the main pipeline notebooks (01-05). Ensure you have:\n",
    "- Completed preprocessing (02_preprocessing.ipynb)\n",
    "- Generated initial features (03_feature_selection.ipynb)\n",
    "- Trained baseline models (04_classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Project-specific imports\n",
    "from src.features import (\n",
    "    TenLevelFeatureSelector,\n",
    "    FeatureSelectionConfig,\n",
    "    StatisticalFeatureSelector,\n",
    "    run_ttest,\n",
    "    run_anova,\n",
    "    calculate_effect_size,\n",
    "    adjust_pvalues\n",
    ")\n",
    "from src.models import (\n",
    "    ClassifierConfig,\n",
    "    BatchAwareClassifier,\n",
    "    CrossValidationStrategy,\n",
    "    ModelEvaluator\n",
    ")\n",
    "from src.enrichment import (\n",
    "    EnrichmentAnalyzer,\n",
    "    EnrichmentConfig,\n",
    "    EPICAnnotationMapper,\n",
    "    MSigDBLoader\n",
    ")\n",
    "from src.visualization import (\n",
    "    plot_pca_visualization,\n",
    "    plot_heatmap,\n",
    "    plot_volcano,\n",
    "    plot_roc_curves,\n",
    "    PublicationFigureGenerator\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATA_DIR = project_root / 'data' / 'raw'\n",
    "PROCESSED_DIR = project_root / 'data' / 'processed'\n",
    "MODELS_DIR = project_root / 'models'\n",
    "RESULTS_DIR = project_root / 'results'\n",
    "FIGURES_DIR = project_root / 'data' / 'figures' / 'custom'\n",
    "\n",
    "# Create output directories\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load preprocessed data\n",
    "with open(PROCESSED_DIR / 'methyl_data_preprocessed.pkl', 'rb') as f:\n",
    "    methylation_data = pickle.load(f)\n",
    "\n",
    "sample_mapping = pd.read_csv(DATA_DIR / 'GSE171140_sample_mapping.csv')\n",
    "\n",
    "print(f\"Loaded data: {methylation_data.shape[0]:,} probes x {methylation_data.shape[1]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom Feature Selection Configurations\n",
    "\n",
    "The `FeatureSelectionConfig` class allows fine-grained control over the feature selection process. Here we demonstrate how to create custom configurations for specific research questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating Custom Stringency Levels\n",
    "\n",
    "The Ten-Level Framework provides predefined stringency levels (L1-L10), but you can create custom configurations for specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomFeatureConfig:\n",
    "    \"\"\"Custom feature selection configuration with flexible parameters.\"\"\"\n",
    "    \n",
    "    # Statistical thresholds\n",
    "    p_value_threshold: float = 0.05\n",
    "    fdr_threshold: float = 0.1\n",
    "    effect_size_threshold: float = 0.3\n",
    "    \n",
    "    # Variance filtering\n",
    "    min_variance: float = 0.01\n",
    "    \n",
    "    # ML-based selection\n",
    "    use_lasso: bool = True\n",
    "    use_random_forest: bool = True\n",
    "    lasso_alpha: float = 0.01\n",
    "    rf_n_estimators: int = 100\n",
    "    rf_importance_threshold: float = 0.001\n",
    "    \n",
    "    # Consensus requirements\n",
    "    min_methods_agreement: int = 2\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"CustomFeatureConfig(p<{self.p_value_threshold}, \"\n",
    "            f\"FDR<{self.fdr_threshold}, |d|>{self.effect_size_threshold})\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Example: Ultra-conservative configuration for publication-quality biomarkers\n",
    "publication_config = CustomFeatureConfig(\n",
    "    p_value_threshold=0.001,\n",
    "    fdr_threshold=0.01,\n",
    "    effect_size_threshold=0.8,  # Large effect size\n",
    "    min_variance=0.02,\n",
    "    min_methods_agreement=3  # Must appear in 3+ selection methods\n",
    ")\n",
    "\n",
    "# Example: Exploratory configuration for pathway discovery\n",
    "exploratory_config = CustomFeatureConfig(\n",
    "    p_value_threshold=0.05,\n",
    "    fdr_threshold=0.2,\n",
    "    effect_size_threshold=0.2,  # Small effect size acceptable\n",
    "    min_variance=0.005,\n",
    "    min_methods_agreement=1  # Any method selection is acceptable\n",
    ")\n",
    "\n",
    "print(\"Publication config:\", publication_config)\n",
    "print(\"Exploratory config:\", exploratory_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Custom Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFeatureSelector:\n",
    "    \"\"\"Custom feature selector with configurable criteria.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: CustomFeatureConfig):\n",
    "        self.config = config\n",
    "        self.selection_results = {}\n",
    "    \n",
    "    def select_features(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        feature_names: List[str]\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Run custom feature selection pipeline.\"\"\"\n",
    "        \n",
    "        results = {\n",
    "            'statistical': set(),\n",
    "            'ml_based': set(),\n",
    "            'consensus': set()\n",
    "        }\n",
    "        \n",
    "        # Step 1: Statistical selection\n",
    "        stat_features = self._statistical_selection(X, y, feature_names)\n",
    "        results['statistical'] = stat_features\n",
    "        \n",
    "        # Step 2: ML-based selection\n",
    "        ml_features = self._ml_selection(X, y, feature_names)\n",
    "        results['ml_based'] = ml_features\n",
    "        \n",
    "        # Step 3: Consensus features\n",
    "        results['consensus'] = self._compute_consensus(\n",
    "            [results['statistical'], results['ml_based']]\n",
    "        )\n",
    "        \n",
    "        self.selection_results = results\n",
    "        return results\n",
    "    \n",
    "    def _statistical_selection(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        feature_names: List[str]\n",
    "    ) -> set:\n",
    "        \"\"\"Apply statistical criteria.\"\"\"\n",
    "        selected = set()\n",
    "        \n",
    "        # Perform t-tests for each feature\n",
    "        p_values = []\n",
    "        effect_sizes = []\n",
    "        \n",
    "        for i in range(X.shape[1]):\n",
    "            group1 = X[y == 0, i]\n",
    "            group2 = X[y == 1, i]\n",
    "            \n",
    "            _, p_val = stats.ttest_ind(group1, group2)\n",
    "            p_values.append(p_val)\n",
    "            \n",
    "            # Cohen's d\n",
    "            pooled_std = np.sqrt(\n",
    "                ((len(group1) - 1) * np.var(group1) + \n",
    "                 (len(group2) - 1) * np.var(group2)) /\n",
    "                (len(group1) + len(group2) - 2)\n",
    "            )\n",
    "            if pooled_std > 0:\n",
    "                d = abs(np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "            else:\n",
    "                d = 0\n",
    "            effect_sizes.append(d)\n",
    "        \n",
    "        # Adjust p-values for multiple testing\n",
    "        from statsmodels.stats.multitest import multipletests\n",
    "        _, fdr_values, _, _ = multipletests(p_values, method='fdr_bh')\n",
    "        \n",
    "        # Select features meeting criteria\n",
    "        for i, name in enumerate(feature_names):\n",
    "            if (fdr_values[i] < self.config.fdr_threshold and\n",
    "                effect_sizes[i] > self.config.effect_size_threshold):\n",
    "                selected.add(name)\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def _ml_selection(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        feature_names: List[str]\n",
    "    ) -> set:\n",
    "        \"\"\"Apply ML-based selection.\"\"\"\n",
    "        selected = set()\n",
    "        \n",
    "        if self.config.use_random_forest:\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            \n",
    "            rf = RandomForestClassifier(\n",
    "                n_estimators=self.config.rf_n_estimators,\n",
    "                random_state=42\n",
    "            )\n",
    "            rf.fit(X, y)\n",
    "            \n",
    "            importances = rf.feature_importances_\n",
    "            for i, name in enumerate(feature_names):\n",
    "                if importances[i] > self.config.rf_importance_threshold:\n",
    "                    selected.add(name)\n",
    "        \n",
    "        if self.config.use_lasso:\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            \n",
    "            lasso = LogisticRegression(\n",
    "                penalty='l1',\n",
    "                solver='saga',\n",
    "                C=1/self.config.lasso_alpha,\n",
    "                random_state=42,\n",
    "                max_iter=1000\n",
    "            )\n",
    "            lasso.fit(StandardScaler().fit_transform(X), y)\n",
    "            \n",
    "            coefs = np.abs(lasso.coef_[0])\n",
    "            for i, name in enumerate(feature_names):\n",
    "                if coefs[i] > 0:\n",
    "                    selected.add(name)\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def _compute_consensus(\n",
    "        self,\n",
    "        feature_sets: List[set]\n",
    "    ) -> set:\n",
    "        \"\"\"Compute consensus features based on method agreement.\"\"\"\n",
    "        from collections import Counter\n",
    "        \n",
    "        # Count occurrences across methods\n",
    "        all_features = []\n",
    "        for feat_set in feature_sets:\n",
    "            all_features.extend(feat_set)\n",
    "        \n",
    "        feature_counts = Counter(all_features)\n",
    "        \n",
    "        # Keep features meeting minimum agreement\n",
    "        consensus = set()\n",
    "        for feature, count in feature_counts.items():\n",
    "            if count >= self.config.min_methods_agreement:\n",
    "                consensus.add(feature)\n",
    "        \n",
    "        return consensus\n",
    "\n",
    "\n",
    "print(\"CustomFeatureSelector class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate custom feature selection\n",
    "\n",
    "# Prepare data\n",
    "sample_ids = methylation_data.columns.tolist()\n",
    "sample_info = sample_mapping.set_index('sample_id').loc[sample_ids].reset_index()\n",
    "\n",
    "binary_mask = sample_info['binary_class'].isin(['HIIT', 'Control'])\n",
    "binary_samples = sample_info[binary_mask]['sample_id'].tolist()\n",
    "binary_labels = (sample_info[binary_mask]['binary_class'] == 'HIIT').astype(int).values\n",
    "\n",
    "# Select subset of features for demonstration\n",
    "feature_subset = methylation_data.index[:5000].tolist()  # First 5000 probes\n",
    "X_demo = methylation_data.loc[feature_subset, binary_samples].T.values\n",
    "y_demo = binary_labels\n",
    "\n",
    "# Run custom selection with exploratory config\n",
    "custom_selector = CustomFeatureSelector(exploratory_config)\n",
    "results = custom_selector.select_features(X_demo, y_demo, feature_subset)\n",
    "\n",
    "print(f\"Statistical selection: {len(results['statistical'])} features\")\n",
    "print(f\"ML-based selection: {len(results['ml_based'])} features\")\n",
    "print(f\"Consensus features: {len(results['consensus'])} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Region-Based Feature Selection\n",
    "\n",
    "Sometimes you may want to select features based on genomic regions (promoters, gene bodies, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionBasedSelector:\n",
    "    \"\"\"Select features based on genomic region annotations.\"\"\"\n",
    "    \n",
    "    def __init__(self, annotation_file: Path):\n",
    "        self.annotation_file = annotation_file\n",
    "        self.annotations = None\n",
    "    \n",
    "    def load_annotations(self) -> pd.DataFrame:\n",
    "        \"\"\"Load EPIC array annotations.\"\"\"\n",
    "        if self.annotation_file.exists():\n",
    "            self.annotations = pd.read_csv(\n",
    "                self.annotation_file,\n",
    "                usecols=['Name', 'CHR', 'MAPINFO', 'UCSC_RefGene_Name', \n",
    "                         'UCSC_RefGene_Group', 'Relation_to_UCSC_CpG_Island']\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Warning: Annotation file not found at {self.annotation_file}\")\n",
    "            self.annotations = pd.DataFrame()\n",
    "        return self.annotations\n",
    "    \n",
    "    def filter_by_region(\n",
    "        self,\n",
    "        probe_ids: List[str],\n",
    "        regions: List[str] = ['TSS200', 'TSS1500', '1stExon']\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Filter probes to specific genomic regions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        probe_ids : List[str]\n",
    "            List of CpG probe IDs\n",
    "        regions : List[str]\n",
    "            Regions to keep. Options include:\n",
    "            - 'TSS200', 'TSS1500': Promoter regions\n",
    "            - '1stExon', '5UTR': Gene start regions\n",
    "            - 'Body', '3UTR': Gene body and end regions\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[str]\n",
    "            Filtered probe IDs\n",
    "        \"\"\"\n",
    "        if self.annotations is None or self.annotations.empty:\n",
    "            return probe_ids\n",
    "        \n",
    "        # Filter annotations to relevant probes\n",
    "        subset = self.annotations[self.annotations['Name'].isin(probe_ids)]\n",
    "        \n",
    "        # Filter by region\n",
    "        filtered = []\n",
    "        for _, row in subset.iterrows():\n",
    "            gene_group = str(row['UCSC_RefGene_Group'])\n",
    "            if any(region in gene_group for region in regions):\n",
    "                filtered.append(row['Name'])\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    def filter_by_cpg_island(\n",
    "        self,\n",
    "        probe_ids: List[str],\n",
    "        relation: str = 'Island'  # 'Island', 'Shore', 'Shelf', 'OpenSea'\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Filter probes by CpG island relationship.\"\"\"\n",
    "        if self.annotations is None or self.annotations.empty:\n",
    "            return probe_ids\n",
    "        \n",
    "        subset = self.annotations[self.annotations['Name'].isin(probe_ids)]\n",
    "        mask = subset['Relation_to_UCSC_CpG_Island'].str.contains(\n",
    "            relation, na=False\n",
    "        )\n",
    "        \n",
    "        return subset.loc[mask, 'Name'].tolist()\n",
    "\n",
    "\n",
    "# Example usage (requires annotation file)\n",
    "annotation_path = project_root / 'data' / 'external' / 'EPIC_manifest.csv'\n",
    "region_selector = RegionBasedSelector(annotation_path)\n",
    "\n",
    "print(\"RegionBasedSelector configured.\")\n",
    "print(\"Use filter_by_region() for promoter/body filtering.\")\n",
    "print(\"Use filter_by_cpg_island() for CpG island context filtering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding Custom Classifiers\n",
    "\n",
    "The pipeline supports extending with custom classifiers. Here we demonstrate how to add new models that integrate with the existing evaluation framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Wrapper for Custom Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Wrapper to integrate custom classifiers with the pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        base_classifier: BaseEstimator,\n",
    "        batch_handling: str = 'none',\n",
    "        scale_features: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_classifier : BaseEstimator\n",
    "            Any scikit-learn compatible classifier\n",
    "        batch_handling : str\n",
    "            How to handle batch effects: 'none', 'covariate', 'stratified'\n",
    "        scale_features : bool\n",
    "            Whether to standardize features before fitting\n",
    "        \"\"\"\n",
    "        self.base_classifier = base_classifier\n",
    "        self.batch_handling = batch_handling\n",
    "        self.scale_features = scale_features\n",
    "        self.scaler = StandardScaler() if scale_features else None\n",
    "        self._batch_encoder = None\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, batch: np.ndarray = None):\n",
    "        \"\"\"Fit the classifier with optional batch handling.\"\"\"\n",
    "        X_processed = X.copy()\n",
    "        \n",
    "        # Handle batch effects\n",
    "        if batch is not None and self.batch_handling == 'covariate':\n",
    "            # Encode batch as numeric and append to features\n",
    "            unique_batches = np.unique(batch)\n",
    "            self._batch_encoder = {b: i for i, b in enumerate(unique_batches)}\n",
    "            batch_encoded = np.array([self._batch_encoder[b] for b in batch]).reshape(-1, 1)\n",
    "            X_processed = np.hstack([X_processed, batch_encoded])\n",
    "        \n",
    "        # Scale features\n",
    "        if self.scaler is not None:\n",
    "            X_processed = self.scaler.fit_transform(X_processed)\n",
    "        \n",
    "        # Fit classifier\n",
    "        self.base_classifier.fit(X_processed, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: np.ndarray, batch: np.ndarray = None) -> np.ndarray:\n",
    "        \"\"\"Make predictions.\"\"\"\n",
    "        X_processed = self._preprocess(X, batch)\n",
    "        return self.base_classifier.predict(X_processed)\n",
    "    \n",
    "    def predict_proba(self, X: np.ndarray, batch: np.ndarray = None) -> np.ndarray:\n",
    "        \"\"\"Predict class probabilities.\"\"\"\n",
    "        X_processed = self._preprocess(X, batch)\n",
    "        return self.base_classifier.predict_proba(X_processed)\n",
    "    \n",
    "    def _preprocess(self, X: np.ndarray, batch: np.ndarray = None) -> np.ndarray:\n",
    "        \"\"\"Apply preprocessing steps.\"\"\"\n",
    "        X_processed = X.copy()\n",
    "        \n",
    "        if batch is not None and self.batch_handling == 'covariate':\n",
    "            batch_encoded = np.array(\n",
    "                [self._batch_encoder.get(b, 0) for b in batch]\n",
    "            ).reshape(-1, 1)\n",
    "            X_processed = np.hstack([X_processed, batch_encoded])\n",
    "        \n",
    "        if self.scaler is not None:\n",
    "            X_processed = self.scaler.transform(X_processed)\n",
    "        \n",
    "        return X_processed\n",
    "    \n",
    "    def get_feature_importance(self) -> np.ndarray:\n",
    "        \"\"\"Get feature importances if available.\"\"\"\n",
    "        if hasattr(self.base_classifier, 'feature_importances_'):\n",
    "            importances = self.base_classifier.feature_importances_\n",
    "            # Remove batch covariate importance if added\n",
    "            if self.batch_handling == 'covariate':\n",
    "                importances = importances[:-1]\n",
    "            return importances\n",
    "        elif hasattr(self.base_classifier, 'coef_'):\n",
    "            coefs = np.abs(self.base_classifier.coef_[0])\n",
    "            if self.batch_handling == 'covariate':\n",
    "                coefs = coefs[:-1]\n",
    "            return coefs\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "print(\"CustomClassifierWrapper defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Adding New Classifier Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new classifier configurations\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_classifier = CustomClassifierWrapper(\n",
    "    base_classifier=GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    batch_handling='covariate',\n",
    "    scale_features=False\n",
    ")\n",
    "\n",
    "# AdaBoost\n",
    "ada_classifier = CustomClassifierWrapper(\n",
    "    base_classifier=AdaBoostClassifier(\n",
    "        n_estimators=50,\n",
    "        learning_rate=1.0,\n",
    "        random_state=42\n",
    "    ),\n",
    "    batch_handling='covariate',\n",
    "    scale_features=True\n",
    ")\n",
    "\n",
    "# Neural Network (MLP)\n",
    "mlp_classifier = CustomClassifierWrapper(\n",
    "    base_classifier=MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 50),\n",
    "        activation='relu',\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    ),\n",
    "    batch_handling='covariate',\n",
    "    scale_features=True\n",
    ")\n",
    "\n",
    "# Collection of classifiers for comparison\n",
    "custom_classifiers = {\n",
    "    'Gradient Boosting': gb_classifier,\n",
    "    'AdaBoost': ada_classifier,\n",
    "    'MLP Neural Network': mlp_classifier\n",
    "}\n",
    "\n",
    "print(\"Custom classifiers configured:\")\n",
    "for name in custom_classifiers:\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Comparing Custom Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_classifiers(\n",
    "    classifiers: Dict[str, BaseEstimator],\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    batch: np.ndarray = None,\n",
    "    cv: int = 5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compare multiple classifiers using cross-validation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    classifiers : Dict[str, BaseEstimator]\n",
    "        Dictionary mapping names to classifier objects\n",
    "    X : np.ndarray\n",
    "        Feature matrix\n",
    "    y : np.ndarray\n",
    "        Labels\n",
    "    batch : np.ndarray, optional\n",
    "        Batch labels for batch-aware training\n",
    "    cv : int\n",
    "        Number of cross-validation folds\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Comparison results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    for name, clf in classifiers.items():\n",
    "        accuracies = []\n",
    "        aucs = []\n",
    "        \n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            if batch is not None:\n",
    "                batch_train = batch[train_idx]\n",
    "                batch_test = batch[test_idx]\n",
    "                clf.fit(X_train, y_train, batch=batch_train)\n",
    "                y_pred = clf.predict(X_test, batch=batch_test)\n",
    "                y_prob = clf.predict_proba(X_test, batch=batch_test)[:, 1]\n",
    "            else:\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_test)\n",
    "                y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            accuracies.append(accuracy_score(y_test, y_pred))\n",
    "            aucs.append(roc_auc_score(y_test, y_prob))\n",
    "        \n",
    "        results.append({\n",
    "            'Classifier': name,\n",
    "            'Accuracy': np.mean(accuracies),\n",
    "            'Accuracy_std': np.std(accuracies),\n",
    "            'AUC': np.mean(aucs),\n",
    "            'AUC_std': np.std(aucs)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print(\"Classifier comparison function defined.\")\n",
    "print(\"Use compare_classifiers() to evaluate multiple models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compare classifiers on the demo data\n",
    "# (Uses subset of features for faster execution)\n",
    "\n",
    "# Get batch information\n",
    "batch_demo = sample_info[binary_mask]['study_group'].values\n",
    "\n",
    "# Compare classifiers\n",
    "comparison_results = compare_classifiers(\n",
    "    custom_classifiers,\n",
    "    X_demo,\n",
    "    y_demo,\n",
    "    batch=batch_demo,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "print(\"\\nClassifier Comparison Results:\")\n",
    "print(comparison_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extended Enrichment Analysis\n",
    "\n",
    "Extend the enrichment analysis with custom gene sets and additional annotation databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Custom Gene Set Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGeneSetAnalyzer:\n",
    "    \"\"\"Perform enrichment analysis with custom gene sets.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.custom_gene_sets = {}\n",
    "    \n",
    "    def add_gene_set(\n",
    "        self,\n",
    "        name: str,\n",
    "        genes: List[str],\n",
    "        category: str = 'custom'\n",
    "    ):\n",
    "        \"\"\"Add a custom gene set for analysis.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            Name of the gene set\n",
    "        genes : List[str]\n",
    "            List of gene symbols\n",
    "        category : str\n",
    "            Category for grouping gene sets\n",
    "        \"\"\"\n",
    "        if category not in self.custom_gene_sets:\n",
    "            self.custom_gene_sets[category] = {}\n",
    "        \n",
    "        self.custom_gene_sets[category][name] = set(genes)\n",
    "    \n",
    "    def load_gmt_file(self, gmt_path: Path, category: str = 'gmt'):\n",
    "        \"\"\"Load gene sets from GMT format file.\n",
    "        \n",
    "        GMT format: gene_set_name<TAB>description<TAB>gene1<TAB>gene2...\n",
    "        \"\"\"\n",
    "        if not gmt_path.exists():\n",
    "            print(f\"Warning: GMT file not found: {gmt_path}\")\n",
    "            return\n",
    "        \n",
    "        if category not in self.custom_gene_sets:\n",
    "            self.custom_gene_sets[category] = {}\n",
    "        \n",
    "        with open(gmt_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 3:\n",
    "                    name = parts[0]\n",
    "                    genes = parts[2:]  # Skip description\n",
    "                    self.custom_gene_sets[category][name] = set(genes)\n",
    "    \n",
    "    def test_enrichment(\n",
    "        self,\n",
    "        query_genes: List[str],\n",
    "        background_genes: List[str],\n",
    "        min_overlap: int = 3\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Test enrichment using Fisher's exact test.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        query_genes : List[str]\n",
    "            Genes to test (e.g., from selected features)\n",
    "        background_genes : List[str]\n",
    "            Background gene set for comparison\n",
    "        min_overlap : int\n",
    "            Minimum overlap required for testing\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Enrichment results with p-values and fold enrichment\n",
    "        \"\"\"\n",
    "        from scipy.stats import fisher_exact\n",
    "        \n",
    "        query_set = set(query_genes)\n",
    "        background_set = set(background_genes)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for category, gene_sets in self.custom_gene_sets.items():\n",
    "            for name, pathway_genes in gene_sets.items():\n",
    "                # Calculate overlap\n",
    "                overlap = query_set & pathway_genes & background_set\n",
    "                \n",
    "                if len(overlap) < min_overlap:\n",
    "                    continue\n",
    "                \n",
    "                # Build contingency table\n",
    "                a = len(overlap)  # Query AND pathway\n",
    "                b = len(query_set & background_set) - a  # Query NOT pathway\n",
    "                c = len(pathway_genes & background_set) - a  # Pathway NOT query\n",
    "                d = len(background_set) - a - b - c  # Neither\n",
    "                \n",
    "                # Fisher's exact test\n",
    "                odds_ratio, p_value = fisher_exact([[a, b], [c, d]], alternative='greater')\n",
    "                \n",
    "                # Fold enrichment\n",
    "                expected = len(query_set) * len(pathway_genes & background_set) / len(background_set)\n",
    "                fold_enrichment = len(overlap) / expected if expected > 0 else 0\n",
    "                \n",
    "                results.append({\n",
    "                    'Category': category,\n",
    "                    'Term': name,\n",
    "                    'Overlap': len(overlap),\n",
    "                    'GeneSet_Size': len(pathway_genes & background_set),\n",
    "                    'Fold_Enrichment': fold_enrichment,\n",
    "                    'P_Value': p_value,\n",
    "                    'Genes': ';'.join(sorted(overlap))\n",
    "                })\n",
    "        \n",
    "        if not results:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Adjust p-values\n",
    "        from statsmodels.stats.multitest import multipletests\n",
    "        _, results_df['FDR'], _, _ = multipletests(\n",
    "            results_df['P_Value'], method='fdr_bh'\n",
    "        )\n",
    "        \n",
    "        return results_df.sort_values('P_Value')\n",
    "\n",
    "\n",
    "print(\"CustomGeneSetAnalyzer defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create analyzer with exercise-related gene sets\n",
    "\n",
    "gene_set_analyzer = CustomGeneSetAnalyzer()\n",
    "\n",
    "# Add custom exercise/metabolism-related gene sets\n",
    "# These are example gene sets - replace with actual research-relevant genes\n",
    "\n",
    "gene_set_analyzer.add_gene_set(\n",
    "    name='Mitochondrial_Biogenesis',\n",
    "    genes=['PPARGC1A', 'TFAM', 'NRF1', 'NRF2', 'ESRRA', 'GABPA'],\n",
    "    category='Exercise_Response'\n",
    ")\n",
    "\n",
    "gene_set_analyzer.add_gene_set(\n",
    "    name='Glucose_Metabolism',\n",
    "    genes=['SLC2A4', 'HK2', 'PFKM', 'PDK4', 'GYS1', 'PYGM'],\n",
    "    category='Exercise_Response'\n",
    ")\n",
    "\n",
    "gene_set_analyzer.add_gene_set(\n",
    "    name='Muscle_Adaptation',\n",
    "    genes=['MYOD1', 'MYF5', 'MYOG', 'MRF4', 'MEF2A', 'MEF2C'],\n",
    "    category='Exercise_Response'\n",
    ")\n",
    "\n",
    "gene_set_analyzer.add_gene_set(\n",
    "    name='Inflammatory_Response',\n",
    "    genes=['IL6', 'TNF', 'IL1B', 'CRP', 'CCL2', 'NFKB1'],\n",
    "    category='Exercise_Response'\n",
    ")\n",
    "\n",
    "print(f\"Added {sum(len(gs) for gs in gene_set_analyzer.custom_gene_sets.values())} gene sets\")\n",
    "for category, gene_sets in gene_set_analyzer.custom_gene_sets.items():\n",
    "    print(f\"  {category}: {len(gene_sets)} sets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Multi-Database Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDatabaseEnrichment:\n",
    "    \"\"\"Run enrichment across multiple databases and combine results.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.databases = {}\n",
    "    \n",
    "    def add_database(\n",
    "        self,\n",
    "        name: str,\n",
    "        analyzer: Any\n",
    "    ):\n",
    "        \"\"\"Add a database/analyzer for enrichment.\"\"\"\n",
    "        self.databases[name] = analyzer\n",
    "    \n",
    "    def run_all(\n",
    "        self,\n",
    "        query_genes: List[str],\n",
    "        background_genes: List[str] = None,\n",
    "        top_n: int = 10\n",
    "    ) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Run enrichment across all databases.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, pd.DataFrame]\n",
    "            Results from each database\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for name, analyzer in self.databases.items():\n",
    "            print(f\"Running enrichment: {name}\")\n",
    "            \n",
    "            try:\n",
    "                if hasattr(analyzer, 'test_enrichment'):\n",
    "                    # Custom gene set analyzer\n",
    "                    result = analyzer.test_enrichment(\n",
    "                        query_genes,\n",
    "                        background_genes or query_genes\n",
    "                    )\n",
    "                elif hasattr(analyzer, 'run_analysis'):\n",
    "                    # Built-in enrichment analyzer\n",
    "                    result = analyzer.run_analysis(query_genes)\n",
    "                else:\n",
    "                    result = pd.DataFrame()\n",
    "                \n",
    "                if not result.empty:\n",
    "                    results[name] = result.head(top_n)\n",
    "                else:\n",
    "                    results[name] = pd.DataFrame({'Message': ['No significant results']})\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"  Error in {name}: {e}\")\n",
    "                results[name] = pd.DataFrame({'Error': [str(e)]})\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def summarize_results(self, results: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "        \"\"\"Create summary table across all databases.\"\"\"\n",
    "        summaries = []\n",
    "        \n",
    "        for db_name, result_df in results.items():\n",
    "            if 'Term' in result_df.columns and 'P_Value' in result_df.columns:\n",
    "                top_term = result_df.iloc[0]\n",
    "                summaries.append({\n",
    "                    'Database': db_name,\n",
    "                    'Top_Term': top_term.get('Term', 'N/A'),\n",
    "                    'P_Value': top_term.get('P_Value', 1.0),\n",
    "                    'Total_Significant': len(result_df[result_df.get('FDR', result_df.get('P_Value', [1.0])) < 0.05])\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(summaries)\n",
    "\n",
    "\n",
    "# Setup multi-database enrichment\n",
    "multi_enrichment = MultiDatabaseEnrichment()\n",
    "multi_enrichment.add_database('Custom_Exercise', gene_set_analyzer)\n",
    "\n",
    "print(\"MultiDatabaseEnrichment configured.\")\n",
    "print(\"Add more databases with add_database() method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom Visualizations\n",
    "\n",
    "Create publication-ready figures with custom styling and layouts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Publication Figure Style Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PublicationStyle:\n",
    "    \"\"\"Configuration for publication-quality figures.\"\"\"\n",
    "    \n",
    "    # Figure dimensions (in inches)\n",
    "    single_column_width: float = 3.5  # Nature/Science single column\n",
    "    double_column_width: float = 7.0  # Full page width\n",
    "    max_height: float = 9.0\n",
    "    \n",
    "    # Font settings\n",
    "    font_family: str = 'Arial'\n",
    "    title_size: int = 10\n",
    "    label_size: int = 9\n",
    "    tick_size: int = 8\n",
    "    legend_size: int = 8\n",
    "    \n",
    "    # Color palette\n",
    "    primary_colors: List[str] = field(default_factory=lambda: [\n",
    "        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'\n",
    "    ])\n",
    "    \n",
    "    # Line and marker settings\n",
    "    line_width: float = 1.5\n",
    "    marker_size: int = 6\n",
    "    \n",
    "    # DPI for saving\n",
    "    save_dpi: int = 300\n",
    "    \n",
    "    def apply(self):\n",
    "        \"\"\"Apply the style settings to matplotlib.\"\"\"\n",
    "        plt.rcParams.update({\n",
    "            'font.family': self.font_family,\n",
    "            'font.size': self.label_size,\n",
    "            'axes.titlesize': self.title_size,\n",
    "            'axes.labelsize': self.label_size,\n",
    "            'xtick.labelsize': self.tick_size,\n",
    "            'ytick.labelsize': self.tick_size,\n",
    "            'legend.fontsize': self.legend_size,\n",
    "            'lines.linewidth': self.line_width,\n",
    "            'lines.markersize': self.marker_size,\n",
    "            'axes.linewidth': 0.8,\n",
    "            'axes.spines.top': False,\n",
    "            'axes.spines.right': False,\n",
    "            'figure.dpi': 100,\n",
    "            'savefig.dpi': self.save_dpi,\n",
    "            'savefig.bbox': 'tight',\n",
    "            'savefig.pad_inches': 0.1\n",
    "        })\n",
    "\n",
    "\n",
    "# Apply publication style\n",
    "pub_style = PublicationStyle()\n",
    "pub_style.apply()\n",
    "\n",
    "print(\"Publication style applied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Custom Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multi_panel_figure(\n",
    "    data_dict: Dict[str, Tuple[np.ndarray, np.ndarray]],\n",
    "    style: PublicationStyle = None,\n",
    "    title: str = None,\n",
    "    save_path: Path = None\n",
    ") -> Tuple[plt.Figure, np.ndarray]:\n",
    "    \"\"\"Create a multi-panel comparison figure.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dict : Dict[str, Tuple[np.ndarray, np.ndarray]]\n",
    "        Dictionary mapping panel names to (x, y) data tuples\n",
    "    style : PublicationStyle, optional\n",
    "        Style configuration\n",
    "    title : str, optional\n",
    "        Figure title\n",
    "    save_path : Path, optional\n",
    "        Path to save the figure\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[plt.Figure, np.ndarray]\n",
    "        Figure and axes array\n",
    "    \"\"\"\n",
    "    if style is None:\n",
    "        style = PublicationStyle()\n",
    "    \n",
    "    n_panels = len(data_dict)\n",
    "    n_cols = min(3, n_panels)\n",
    "    n_rows = (n_panels + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows, n_cols,\n",
    "        figsize=(style.single_column_width * n_cols, 3 * n_rows)\n",
    "    )\n",
    "    \n",
    "    if n_panels == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (name, (x_data, y_data)) in enumerate(data_dict.items()):\n",
    "        ax = axes[idx]\n",
    "        ax.scatter(x_data, y_data, alpha=0.6, c=style.primary_colors[idx % len(style.primary_colors)])\n",
    "        ax.set_title(name)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "    \n",
    "    # Hide unused axes\n",
    "    for idx in range(n_panels, len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=style.title_size + 2, y=1.02)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=style.save_dpi, bbox_inches='tight')\n",
    "        print(f\"Figure saved to: {save_path}\")\n",
    "    \n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "print(\"Custom visualization functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_enrichment_dotplot(\n",
    "    enrichment_df: pd.DataFrame,\n",
    "    x_col: str = 'Fold_Enrichment',\n",
    "    y_col: str = 'Term',\n",
    "    size_col: str = 'Overlap',\n",
    "    color_col: str = 'P_Value',\n",
    "    title: str = 'Enrichment Analysis',\n",
    "    max_terms: int = 15,\n",
    "    save_path: Path = None\n",
    ") -> Tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"Create a dot plot for enrichment results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    enrichment_df : pd.DataFrame\n",
    "        Enrichment results with required columns\n",
    "    x_col : str\n",
    "        Column for x-axis (typically fold enrichment)\n",
    "    y_col : str\n",
    "        Column for y-axis (term names)\n",
    "    size_col : str\n",
    "        Column for dot size (typically overlap count)\n",
    "    color_col : str\n",
    "        Column for dot color (typically p-value)\n",
    "    title : str\n",
    "        Plot title\n",
    "    max_terms : int\n",
    "        Maximum number of terms to display\n",
    "    save_path : Path, optional\n",
    "        Path to save the figure\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[plt.Figure, plt.Axes]\n",
    "        Figure and axes\n",
    "    \"\"\"\n",
    "    if enrichment_df.empty:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.text(0.5, 0.5, 'No enrichment results to display',\n",
    "                ha='center', va='center', transform=ax.transAxes)\n",
    "        return fig, ax\n",
    "    \n",
    "    # Prepare data\n",
    "    plot_df = enrichment_df.head(max_terms).copy()\n",
    "    plot_df = plot_df.iloc[::-1]  # Reverse for top-to-bottom display\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 0.4 * len(plot_df) + 2))\n",
    "    \n",
    "    # Create scatter plot\n",
    "    scatter = ax.scatter(\n",
    "        plot_df[x_col],\n",
    "        range(len(plot_df)),\n",
    "        s=plot_df[size_col] * 20,  # Scale size\n",
    "        c=-np.log10(plot_df[color_col]),  # -log10 p-value\n",
    "        cmap='RdYlBu_r',\n",
    "        alpha=0.8,\n",
    "        edgecolors='black',\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    \n",
    "    # Customize axes\n",
    "    ax.set_yticks(range(len(plot_df)))\n",
    "    ax.set_yticklabels(plot_df[y_col])\n",
    "    ax.set_xlabel(x_col.replace('_', ' '))\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax, shrink=0.6)\n",
    "    cbar.set_label('-log10(P-value)')\n",
    "    \n",
    "    # Add size legend\n",
    "    sizes = [5, 10, 20]\n",
    "    for size in sizes:\n",
    "        ax.scatter([], [], s=size * 20, c='gray', alpha=0.6,\n",
    "                   label=f'{size} genes', edgecolors='black', linewidths=0.5)\n",
    "    ax.legend(title='Overlap', loc='lower right', framealpha=0.9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Figure saved to: {save_path}\")\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "print(\"Enrichment dot plot function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Composite Figure Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_composite_figure(\n",
    "    panels: Dict[str, Tuple[callable, Dict]],\n",
    "    layout: Tuple[int, int] = None,\n",
    "    figsize: Tuple[float, float] = None,\n",
    "    save_path: Path = None\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Create a composite figure with multiple panel types.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    panels : Dict[str, Tuple[callable, Dict]]\n",
    "        Dictionary mapping panel labels (A, B, C...) to\n",
    "        (plotting_function, kwargs) tuples\n",
    "    layout : Tuple[int, int], optional\n",
    "        Grid layout (rows, cols)\n",
    "    figsize : Tuple[float, float], optional\n",
    "        Figure size in inches\n",
    "    save_path : Path, optional\n",
    "        Path to save the figure\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        The composite figure\n",
    "    \"\"\"\n",
    "    n_panels = len(panels)\n",
    "    \n",
    "    if layout is None:\n",
    "        n_cols = min(2, n_panels)\n",
    "        n_rows = (n_panels + n_cols - 1) // n_cols\n",
    "        layout = (n_rows, n_cols)\n",
    "    \n",
    "    if figsize is None:\n",
    "        figsize = (7 * layout[1], 5 * layout[0])\n",
    "    \n",
    "    fig, axes = plt.subplots(layout[0], layout[1], figsize=figsize)\n",
    "    \n",
    "    if n_panels == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (label, (plot_func, kwargs)) in enumerate(panels.items()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Add panel label\n",
    "        ax.text(-0.1, 1.1, label, transform=ax.transAxes,\n",
    "                fontsize=14, fontweight='bold', va='top')\n",
    "        \n",
    "        # Execute plotting function\n",
    "        try:\n",
    "            plot_func(ax=ax, **kwargs)\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f'Error: {str(e)[:50]}',\n",
    "                    ha='center', va='center', transform=ax.transAxes)\n",
    "    \n",
    "    # Hide unused axes\n",
    "    for idx in range(n_panels, len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Composite figure saved to: {save_path}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "print(\"Composite figure function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline Extensions\n",
    "\n",
    "Integrate external tools and create custom analysis workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 External Tool Integration Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExternalToolIntegration:\n",
    "    \"\"\"Template for integrating external bioinformatics tools.\"\"\"\n",
    "    \n",
    "    def __init__(self, tool_path: str = None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        tool_path : str, optional\n",
    "            Path to the external tool executable\n",
    "        \"\"\"\n",
    "        self.tool_path = tool_path\n",
    "        self.results = None\n",
    "    \n",
    "    def prepare_input(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        output_path: Path,\n",
    "        format: str = 'tsv'\n",
    "    ) -> Path:\n",
    "        \"\"\"Prepare input file for external tool.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : pd.DataFrame\n",
    "            Data to export\n",
    "        output_path : Path\n",
    "            Output file path\n",
    "        format : str\n",
    "            Output format ('tsv', 'csv', 'bed')\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Path\n",
    "            Path to the prepared file\n",
    "        \"\"\"\n",
    "        output_path = Path(output_path)\n",
    "        \n",
    "        if format == 'tsv':\n",
    "            data.to_csv(output_path, sep='\\t', index=False)\n",
    "        elif format == 'csv':\n",
    "            data.to_csv(output_path, index=False)\n",
    "        elif format == 'bed':\n",
    "            # BED format: chr, start, end, name, score, strand\n",
    "            if all(col in data.columns for col in ['chr', 'start', 'end']):\n",
    "                data[['chr', 'start', 'end']].to_csv(\n",
    "                    output_path, sep='\\t', index=False, header=False\n",
    "                )\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def run_tool(self, input_path: Path, **kwargs) -> str:\n",
    "        \"\"\"Run the external tool.\n",
    "        \n",
    "        This is a template - override in subclass for specific tools.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_path : Path\n",
    "            Path to input file\n",
    "        **kwargs\n",
    "            Additional tool-specific arguments\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Tool output or path to output file\n",
    "        \"\"\"\n",
    "        import subprocess\n",
    "        \n",
    "        if self.tool_path is None:\n",
    "            raise ValueError(\"Tool path not specified\")\n",
    "        \n",
    "        cmd = [self.tool_path, str(input_path)]\n",
    "        \n",
    "        # Add additional arguments\n",
    "        for key, value in kwargs.items():\n",
    "            cmd.extend([f'--{key}', str(value)])\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise RuntimeError(f\"Tool failed: {result.stderr}\")\n",
    "        \n",
    "        return result.stdout\n",
    "    \n",
    "    def parse_output(\n",
    "        self,\n",
    "        output: str,\n",
    "        format: str = 'tsv'\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Parse tool output into DataFrame.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        output : str\n",
    "            Tool output string or path to output file\n",
    "        format : str\n",
    "            Output format\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Parsed results\n",
    "        \"\"\"\n",
    "        output_path = Path(output)\n",
    "        \n",
    "        if output_path.exists():\n",
    "            if format == 'tsv':\n",
    "                return pd.read_csv(output_path, sep='\\t')\n",
    "            elif format == 'csv':\n",
    "                return pd.read_csv(output_path)\n",
    "        else:\n",
    "            # Parse string output\n",
    "            from io import StringIO\n",
    "            return pd.read_csv(StringIO(output), sep='\\t')\n",
    "\n",
    "\n",
    "print(\"ExternalToolIntegration template defined.\")\n",
    "print(\"Subclass this for specific tools (HOMER, GREAT, etc.).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Custom Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAnalysisPipeline:\n",
    "    \"\"\"Template for creating custom analysis pipelines.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict[str, Any] = None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        config : Dict[str, Any], optional\n",
    "            Pipeline configuration\n",
    "        \"\"\"\n",
    "        self.config = config or {}\n",
    "        self.steps = []\n",
    "        self.results = {}\n",
    "    \n",
    "    def add_step(\n",
    "        self,\n",
    "        name: str,\n",
    "        function: callable,\n",
    "        depends_on: List[str] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Add a step to the pipeline.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            Step name (used as key in results)\n",
    "        function : callable\n",
    "            Function to execute\n",
    "        depends_on : List[str], optional\n",
    "            Names of steps this depends on\n",
    "        **kwargs\n",
    "            Additional arguments for the function\n",
    "        \"\"\"\n",
    "        self.steps.append({\n",
    "            'name': name,\n",
    "            'function': function,\n",
    "            'depends_on': depends_on or [],\n",
    "            'kwargs': kwargs\n",
    "        })\n",
    "    \n",
    "    def run(self, initial_data: Any = None) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the pipeline.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        initial_data : Any, optional\n",
    "            Initial data to pass to first step\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Results from all steps\n",
    "        \"\"\"\n",
    "        self.results = {'initial': initial_data}\n",
    "        \n",
    "        for step in self.steps:\n",
    "            print(f\"Running step: {step['name']}\")\n",
    "            \n",
    "            # Gather inputs from dependencies\n",
    "            inputs = {}\n",
    "            for dep in step['depends_on']:\n",
    "                if dep in self.results:\n",
    "                    inputs[dep] = self.results[dep]\n",
    "                else:\n",
    "                    raise ValueError(f\"Dependency '{dep}' not found\")\n",
    "            \n",
    "            # Add initial data if no dependencies\n",
    "            if not inputs and initial_data is not None:\n",
    "                inputs['data'] = initial_data\n",
    "            \n",
    "            # Execute step\n",
    "            try:\n",
    "                result = step['function'](**inputs, **step['kwargs'])\n",
    "                self.results[step['name']] = result\n",
    "                print(f\"  Completed: {step['name']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error in {step['name']}: {e}\")\n",
    "                self.results[step['name']] = None\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def get_result(self, step_name: str) -> Any:\n",
    "        \"\"\"Get result from a specific step.\"\"\"\n",
    "        return self.results.get(step_name)\n",
    "    \n",
    "    def summarize(self) -> pd.DataFrame:\n",
    "        \"\"\"Create summary of pipeline execution.\"\"\"\n",
    "        summary = []\n",
    "        for step in self.steps:\n",
    "            result = self.results.get(step['name'])\n",
    "            summary.append({\n",
    "                'Step': step['name'],\n",
    "                'Status': 'Success' if result is not None else 'Failed',\n",
    "                'Result_Type': type(result).__name__ if result is not None else 'None'\n",
    "            })\n",
    "        return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "print(\"CustomAnalysisPipeline template defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a custom pipeline\n",
    "\n",
    "def step_filter_features(data: pd.DataFrame, variance_threshold: float = 0.01):\n",
    "    \"\"\"Example step: filter by variance.\"\"\"\n",
    "    variances = data.var(axis=1)\n",
    "    return data.loc[variances > variance_threshold]\n",
    "\n",
    "def step_select_top(step_filter_features: pd.DataFrame, n_top: int = 100):\n",
    "    \"\"\"Example step: select top variable features.\"\"\"\n",
    "    variances = step_filter_features.var(axis=1)\n",
    "    top_features = variances.nlargest(n_top).index\n",
    "    return step_filter_features.loc[top_features]\n",
    "\n",
    "def step_summarize(step_select_top: pd.DataFrame):\n",
    "    \"\"\"Example step: create summary statistics.\"\"\"\n",
    "    return {\n",
    "        'n_features': len(step_select_top),\n",
    "        'mean_variance': step_select_top.var(axis=1).mean()\n",
    "    }\n",
    "\n",
    "# Build pipeline\n",
    "pipeline = CustomAnalysisPipeline()\n",
    "pipeline.add_step('step_filter_features', step_filter_features, variance_threshold=0.01)\n",
    "pipeline.add_step('step_select_top', step_select_top, depends_on=['step_filter_features'], n_top=50)\n",
    "pipeline.add_step('step_summarize', step_summarize, depends_on=['step_select_top'])\n",
    "\n",
    "print(\"Example pipeline configured with 3 steps.\")\n",
    "print(\"Run with: pipeline.run(methylation_data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Putting It All Together\n",
    "\n",
    "Example of a complete custom analysis workflow combining the techniques above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_custom_analysis(\n",
    "    methylation_data: pd.DataFrame,\n",
    "    sample_mapping: pd.DataFrame,\n",
    "    feature_config: CustomFeatureConfig = None,\n",
    "    output_dir: Path = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run a complete custom analysis workflow.\n",
    "    \n",
    "    This demonstrates how to combine custom configurations,\n",
    "    classifiers, and visualizations into a cohesive analysis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    methylation_data : pd.DataFrame\n",
    "        Preprocessed methylation data (probes x samples)\n",
    "    sample_mapping : pd.DataFrame\n",
    "        Sample metadata\n",
    "    feature_config : CustomFeatureConfig, optional\n",
    "        Custom feature selection configuration\n",
    "    output_dir : Path, optional\n",
    "        Directory to save outputs\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        Analysis results\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Step 1: Prepare data\n",
    "    print(\"Step 1: Preparing data...\")\n",
    "    sample_ids = methylation_data.columns.tolist()\n",
    "    sample_info = sample_mapping.set_index('sample_id').loc[sample_ids].reset_index()\n",
    "    \n",
    "    binary_mask = sample_info['binary_class'].isin(['HIIT', 'Control'])\n",
    "    binary_samples = sample_info[binary_mask]['sample_id'].tolist()\n",
    "    binary_labels = (sample_info[binary_mask]['binary_class'] == 'HIIT').astype(int).values\n",
    "    batch = sample_info[binary_mask]['study_group'].values\n",
    "    \n",
    "    results['n_samples'] = len(binary_samples)\n",
    "    results['n_features_initial'] = methylation_data.shape[0]\n",
    "    \n",
    "    # Step 2: Custom feature selection\n",
    "    print(\"Step 2: Running custom feature selection...\")\n",
    "    if feature_config is None:\n",
    "        feature_config = CustomFeatureConfig()\n",
    "    \n",
    "    feature_names = methylation_data.index.tolist()\n",
    "    X = methylation_data[binary_samples].T.values\n",
    "    y = binary_labels\n",
    "    \n",
    "    selector = CustomFeatureSelector(feature_config)\n",
    "    selection_results = selector.select_features(X, y, feature_names)\n",
    "    \n",
    "    results['features_statistical'] = len(selection_results['statistical'])\n",
    "    results['features_ml'] = len(selection_results['ml_based'])\n",
    "    results['features_consensus'] = len(selection_results['consensus'])\n",
    "    \n",
    "    # Step 3: Train and evaluate classifiers\n",
    "    print(\"Step 3: Training classifiers...\")\n",
    "    \n",
    "    # Use consensus features\n",
    "    selected_features = list(selection_results['consensus'])\n",
    "    if len(selected_features) == 0:\n",
    "        selected_features = list(selection_results['statistical'])[:100]\n",
    "    \n",
    "    available_features = [f for f in selected_features if f in methylation_data.index]\n",
    "    X_selected = methylation_data.loc[available_features, binary_samples].T.values\n",
    "    \n",
    "    # Compare classifiers\n",
    "    classifiers = {\n",
    "        'Gradient Boosting': CustomClassifierWrapper(\n",
    "            GradientBoostingClassifier(n_estimators=50, random_state=42),\n",
    "            batch_handling='covariate'\n",
    "        ),\n",
    "        'MLP': CustomClassifierWrapper(\n",
    "            MLPClassifier(hidden_layer_sizes=(50,), max_iter=300, random_state=42),\n",
    "            batch_handling='covariate'\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    comparison = compare_classifiers(classifiers, X_selected, y, batch=batch, cv=5)\n",
    "    results['classifier_comparison'] = comparison\n",
    "    \n",
    "    # Step 4: Save outputs\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save feature lists\n",
    "        pd.DataFrame({'probe_id': list(selection_results['consensus'])}).to_csv(\n",
    "            output_dir / 'consensus_features.csv', index=False\n",
    "        )\n",
    "        \n",
    "        # Save classifier comparison\n",
    "        comparison.to_csv(output_dir / 'classifier_comparison.csv', index=False)\n",
    "        \n",
    "        print(f\"Results saved to: {output_dir}\")\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Complete custom analysis function defined.\")\n",
    "print(\"Run with: run_complete_custom_analysis(methylation_data, sample_mapping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated advanced customization options for the HIIT methylation analysis pipeline:\n",
    "\n",
    "### Key Customizations Covered\n",
    "\n",
    "1. **Feature Selection**\n",
    "   - Custom stringency configurations\n",
    "   - Region-based filtering (promoters, gene bodies)\n",
    "   - Multi-method consensus selection\n",
    "\n",
    "2. **Classifiers**\n",
    "   - Wrapper for integrating new models\n",
    "   - Gradient Boosting, AdaBoost, MLP examples\n",
    "   - Batch-aware training support\n",
    "\n",
    "3. **Enrichment Analysis**\n",
    "   - Custom gene set creation\n",
    "   - GMT file loading\n",
    "   - Multi-database analysis\n",
    "\n",
    "4. **Visualizations**\n",
    "   - Publication-quality styling\n",
    "   - Multi-panel figures\n",
    "   - Enrichment dot plots\n",
    "\n",
    "5. **Pipeline Extensions**\n",
    "   - External tool integration template\n",
    "   - Custom analysis pipelines\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Adapt these templates to your specific research questions\n",
    "- Add domain-specific gene sets for enrichment\n",
    "- Integrate additional external tools as needed\n",
    "- Create custom visualization styles for your publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session summary\n",
    "print(\"=\" * 60)\n",
    "print(\"CUSTOM ANALYSIS NOTEBOOK READY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nCustomization options demonstrated:\")\n",
    "print(\"  - CustomFeatureConfig: Flexible feature selection\")\n",
    "print(\"  - CustomClassifierWrapper: New model integration\")\n",
    "print(\"  - CustomGeneSetAnalyzer: Custom enrichment\")\n",
    "print(\"  - PublicationStyle: Figure formatting\")\n",
    "print(\"  - CustomAnalysisPipeline: Workflow automation\")\n",
    "print(\"\\nRefer to the main pipeline notebooks (01-05) for\")\n",
    "print(\"standard analysis workflows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
