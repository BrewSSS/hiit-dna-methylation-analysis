{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: Complete HIIT Methylation Analysis Pipeline\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides a condensed walkthrough of the complete HIIT methylation analysis pipeline. It demonstrates how to go from raw GEO data to classification results and biological interpretation in a streamlined workflow.\n",
    "\n",
    "For detailed explanations and methodology discussions, refer to the individual notebooks (01-05).\n",
    "\n",
    "### Pipeline Steps\n",
    "\n",
    "1. Data Acquisition\n",
    "2. Preprocessing\n",
    "3. Feature Selection (Ten-Level Framework)\n",
    "4. Classification\n",
    "5. Enrichment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = project_root / 'data' / 'raw'\n",
    "PROCESSED_DIR = project_root / 'data' / 'processed'\n",
    "MODELS_DIR = project_root / 'models'\n",
    "RESULTS_DIR = project_root / 'results'\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [DATA_DIR, PROCESSED_DIR, MODELS_DIR, RESULTS_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Acquisition\n",
    "\n",
    "Download and load the GSE171140 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.loader import GEODataLoader\n",
    "from src.data.sample_mapping import SampleMapper\n",
    "\n",
    "# Initialize loader and download data\n",
    "loader = GEODataLoader('GSE171140', data_dir=DATA_DIR)\n",
    "\n",
    "# Download and extract (skip if already exists)\n",
    "loader.download_series_matrix(force=False)\n",
    "loader.extract_gz_file(force=False)\n",
    "\n",
    "# Load methylation data and metadata\n",
    "methylation_data = loader.load_methylation_matrix()\n",
    "metadata = loader.get_metadata()\n",
    "\n",
    "# Create sample mapping\n",
    "mapper = SampleMapper()\n",
    "sample_mapping = mapper.create_sample_mapping(\n",
    "    metadata, \n",
    "    output_path=str(DATA_DIR / 'sample_mapping.csv')\n",
    ")\n",
    "\n",
    "print(f\"\\nData loaded: {methylation_data.shape[0]:,} probes x {methylation_data.shape[1]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing\n",
    "\n",
    "Filter low-variance probes and handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocessing import MethylationPreprocessor, normalize_beta_values\n",
    "\n",
    "# Normalize beta values\n",
    "methylation_normalized = normalize_beta_values(methylation_data)\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = MethylationPreprocessor(\n",
    "    std_threshold=0.02,\n",
    "    missing_threshold=0.2\n",
    ")\n",
    "\n",
    "# Filter and impute\n",
    "filtered_data = preprocessor.filter_low_variance(methylation_normalized)\n",
    "imputed_data = preprocessor.handle_missing_values(filtered_data, strategy='median')\n",
    "\n",
    "# Create data versions\n",
    "batch_info = sample_mapping.set_index('sample_id').loc[\n",
    "    imputed_data.columns, 'study_group'\n",
    "]\n",
    "data_versions = preprocessor.create_data_versions(imputed_data, batch_info)\n",
    "\n",
    "# Save preprocessed data\n",
    "with open(PROCESSED_DIR / 'methyl_data_preprocessed.pkl', 'wb') as f:\n",
    "    pickle.dump(imputed_data, f)\n",
    "\n",
    "print(f\"Preprocessed: {imputed_data.shape[0]:,} probes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Selection\n",
    "\n",
    "Apply the Ten-Level Feature Selection Framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import TenLevelFeatureSelector, FeatureSelectionConfig\n",
    "\n",
    "# Prepare data for binary classification\n",
    "sample_ids = imputed_data.columns.tolist()\n",
    "sample_info = sample_mapping.set_index('sample_id').loc[sample_ids].reset_index()\n",
    "\n",
    "binary_mask = sample_info['binary_class'].isin(['HIIT', 'Control'])\n",
    "binary_samples = sample_info[binary_mask]['sample_id'].tolist()\n",
    "binary_labels = (sample_info[binary_mask]['binary_class'] == 'HIIT').astype(int).values\n",
    "\n",
    "# Extract feature matrix\n",
    "X = imputed_data[binary_samples].T.values\n",
    "y = binary_labels\n",
    "\n",
    "# Initialize selector\n",
    "config = FeatureSelectionConfig()\n",
    "selector = TenLevelFeatureSelector(config)\n",
    "\n",
    "# Select features at moderate stringency\n",
    "selected_features = selector.select_binary_features(\n",
    "    X, y, level='L5_moderate'\n",
    ")\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features at L5 stringency\")\n",
    "\n",
    "# Save features\n",
    "features_dir = PROCESSED_DIR / 'features'\n",
    "features_dir.mkdir(exist_ok=True)\n",
    "pd.DataFrame({'probe_id': list(selected_features)}).to_csv(\n",
    "    features_dir / 'selected_features.csv', index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Classification\n",
    "\n",
    "Train and evaluate batch-aware classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import (\n",
    "    ClassifierConfig,\n",
    "    BatchAwareClassifier,\n",
    "    CrossValidationStrategy\n",
    ")\n",
    "\n",
    "# Prepare feature matrix with selected features\n",
    "available_features = [f for f in selected_features if f in imputed_data.index]\n",
    "X_selected = imputed_data.loc[available_features, binary_samples].T.values\n",
    "batch = sample_info[binary_mask]['study_group'].values\n",
    "\n",
    "# Configure and train classifier\n",
    "clf_config = ClassifierConfig(\n",
    "    classifier_type='random_forest',\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "classifier = BatchAwareClassifier(\n",
    "    config=clf_config,\n",
    "    batch_handling='covariate'\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "cv_strategy = CrossValidationStrategy(n_splits=5, n_repeats=10, random_state=42)\n",
    "cv_results = cv_strategy.evaluate(classifier, X_selected, y, batch=batch)\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"  Accuracy: {cv_results['accuracy_mean']:.3f} +/- {cv_results['accuracy_std']:.3f}\")\n",
    "print(f\"  AUC-ROC: {cv_results['auc_mean']:.3f} +/- {cv_results['auc_std']:.3f}\")\n",
    "\n",
    "# Train final model and save\n",
    "classifier.fit(X_selected, y, batch=batch)\n",
    "with open(MODELS_DIR / 'classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Enrichment Analysis\n",
    "\n",
    "Perform functional enrichment on selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.enrichment import EnrichmentAnalyzer, EPICAnnotationMapper\n",
    "\n",
    "# Map CpGs to genes\n",
    "annotation_mapper = EPICAnnotationMapper(\n",
    "    annotation_file=project_root / 'data' / 'external' / 'EPIC_manifest.csv'\n",
    ")\n",
    "genes = annotation_mapper.map_probes_to_genes(available_features)\n",
    "\n",
    "print(f\"Mapped {len(available_features)} CpGs to {len(genes)} genes\")\n",
    "\n",
    "# Run enrichment analysis\n",
    "analyzer = EnrichmentAnalyzer()\n",
    "results = analyzer.run_comprehensive_analysis(cpg_sites=available_features)\n",
    "\n",
    "# Save results\n",
    "enrichment_dir = RESULTS_DIR / 'enrichment'\n",
    "enrichment_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if 'GO' in results and 'BP' in results['GO']:\n",
    "    results['GO']['BP'].to_csv(enrichment_dir / 'go_bp_results.csv', index=False)\n",
    "    print(f\"\\nTop enriched biological processes saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nData:\")\n",
    "print(f\"  Original probes: {methylation_data.shape[0]:,}\")\n",
    "print(f\"  After preprocessing: {imputed_data.shape[0]:,}\")\n",
    "print(f\"  Samples: {len(binary_samples)}\")\n",
    "\n",
    "print(f\"\\nFeature Selection:\")\n",
    "print(f\"  Selected features: {len(selected_features)}\")\n",
    "\n",
    "print(f\"\\nClassification:\")\n",
    "print(f\"  CV Accuracy: {cv_results['accuracy_mean']:.3f}\")\n",
    "print(f\"  CV AUC-ROC: {cv_results['auc_mean']:.3f}\")\n",
    "\n",
    "print(f\"\\nEnrichment:\")\n",
    "print(f\"  Genes analyzed: {len(genes)}\")\n",
    "\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  - {PROCESSED_DIR / 'methyl_data_preprocessed.pkl'}\")\n",
    "print(f\"  - {features_dir / 'selected_features.csv'}\")\n",
    "print(f\"  - {MODELS_DIR / 'classifier.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "For more detailed analysis:\n",
    "\n",
    "1. **01_data_acquisition.ipynb**: Understanding the experimental design\n",
    "2. **02_preprocessing.ipynb**: Quality control and batch effect analysis\n",
    "3. **03_feature_selection.ipynb**: Exploring different stringency levels\n",
    "4. **04_classification.ipynb**: Model comparison and feature importance\n",
    "5. **05_enrichment_analysis.ipynb**: Biological interpretation\n",
    "\n",
    "For customization:\n",
    "- See **examples/custom_analysis.ipynb** for advanced configurations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
