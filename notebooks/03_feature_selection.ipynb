{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection: The Ten-Level Framework\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates the **Ten-Level Feature Selection Framework**, a novel methodology for robust and reproducible DNA methylation biomarker identification. The framework provides graduated stringency levels that enable researchers to balance between discovery power and reproducibility.\n",
    "\n",
    "### The Ten-Level Framework\n",
    "\n",
    "The framework defines ten stringency levels, each with calibrated thresholds for:\n",
    "\n",
    "| Level | Name | P-value | Effect Size | Use Case |\n",
    "|-------|------|---------|-------------|----------|\n",
    "| L1 | Discovery | 0.05 | 0.2 | Initial exploration |\n",
    "| L2 | Liberal | 0.01 | 0.3 | Hypothesis generation |\n",
    "| L3 | Standard | 0.005 | 0.4 | Standard analysis |\n",
    "| L4 | Conservative | 0.001 | 0.5 | Robust features |\n",
    "| L5 | Moderate | 0.001 | 0.5 | Balanced approach |\n",
    "| L6 | Stringent | 0.0005 | 0.6 | High confidence |\n",
    "| L7 | Very Stringent | 0.0001 | 0.7 | Publication quality |\n",
    "| L8 | Ultra | 0.00005 | 0.8 | High replication potential |\n",
    "| L9 | Extreme | 0.00001 | 0.9 | Very stringent filtering |\n",
    "| L10 | Maximum | 0.000001 | 1.0 | Maximum stringency |\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Configure and apply the Ten-Level Feature Selection Framework\n",
    "2. Perform binary feature selection (HIIT vs Control)\n",
    "3. Perform multiclass feature selection (4W/8W/12W duration)\n",
    "4. Analyze time-series methylation trajectories\n",
    "5. Identify consensus features across methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Project-specific imports - Feature Selection Framework\n",
    "from src.features import (\n",
    "    TenLevelFeatureSelector,\n",
    "    FeatureSelectionConfig,\n",
    "    StatisticalFeatureSelector,\n",
    "    LassoFeatureSelector,\n",
    "    ElasticNetFeatureSelector,\n",
    "    RandomForestFeatureSelector,\n",
    "    TimeSeriesFeatureAnalyzer,\n",
    "    run_ttest,\n",
    "    run_anova,\n",
    "    calculate_effect_size,\n",
    "    adjust_pvalues\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "from src.visualization import (\n",
    "    plot_volcano,\n",
    "    plot_heatmap,\n",
    "    plot_feature_importance\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define paths\n",
    "processed_dir = project_root / 'data' / 'processed'\n",
    "features_dir = processed_dir / 'features'\n",
    "figures_dir = project_root / 'data' / 'figures' / 'feature_importance'\n",
    "\n",
    "# Create output directories\n",
    "features_dir.mkdir(parents=True, exist_ok=True)\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load preprocessed methylation data\n",
    "with open(processed_dir / 'methyl_data_preprocessed.pkl', 'rb') as f:\n",
    "    methylation_data = pickle.load(f)\n",
    "\n",
    "# Load sample mapping\n",
    "sample_mapping = pd.read_csv(\n",
    "    project_root / 'data' / 'raw' / 'GSE171140_sample_mapping.csv'\n",
    ")\n",
    "\n",
    "print(f\"Methylation data: {methylation_data.shape[0]:,} probes x {methylation_data.shape[1]} samples\")\n",
    "print(f\"Sample mapping: {len(sample_mapping)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Feature Selection\n",
    "\n",
    "Organize samples into appropriate groups for each classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align sample mapping with methylation data\n",
    "sample_ids = methylation_data.columns.tolist()\n",
    "sample_info = sample_mapping.set_index('sample_id').loc[sample_ids].reset_index()\n",
    "\n",
    "# Create binary labels\n",
    "binary_mask = sample_info['binary_class'].isin(['HIIT', 'Control'])\n",
    "binary_samples = sample_info[binary_mask]['sample_id'].tolist()\n",
    "binary_labels = sample_info[binary_mask]['binary_class'].values\n",
    "\n",
    "# Create multiclass labels (HIIT duration)\n",
    "multiclass_mask = sample_info['multi_class'].notna()\n",
    "multiclass_samples = sample_info[multiclass_mask]['sample_id'].tolist()\n",
    "multiclass_labels = sample_info[multiclass_mask]['multi_class'].values\n",
    "\n",
    "print(\"Binary Classification Dataset:\")\n",
    "print(f\"  HIIT samples: {sum(binary_labels == 'HIIT')}\")\n",
    "print(f\"  Control samples: {sum(binary_labels == 'Control')}\")\n",
    "\n",
    "print(f\"\\nMulticlass Classification Dataset:\")\n",
    "for cls in ['4W', '8W', '12W']:\n",
    "    print(f\"  {cls}: {sum(multiclass_labels == cls)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize the Ten-Level Feature Selector\n",
    "\n",
    "The `TenLevelFeatureSelector` is the main orchestrator of the framework. It integrates multiple selection methods and provides unified access to all stringency levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration for the selector\n",
    "config = FeatureSelectionConfig()\n",
    "\n",
    "# Display available levels\n",
    "print(\"Available Stringency Levels:\")\n",
    "print(\"=\" * 60)\n",
    "for level_name, level_config in config.levels.items():\n",
    "    print(f\"{level_name}: p-value={level_config['p_value']}, \"\n",
    "          f\"effect_size={level_config['effect_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Ten-Level Feature Selector\n",
    "selector = TenLevelFeatureSelector(config)\n",
    "\n",
    "print(\"Ten-Level Feature Selector initialized.\")\n",
    "print(f\"\\nSelection methods available:\")\n",
    "print(\"  - Statistical: t-test, ANOVA with FDR correction\")\n",
    "print(\"  - Machine Learning: LASSO, Elastic Net, Random Forest\")\n",
    "print(\"  - Time-series: Trajectory analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Binary Feature Selection: HIIT vs Control\n",
    "\n",
    "We apply the framework to identify CpG sites that differentiate HIIT intervention samples from control/baseline samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract binary classification data\n",
    "X_binary = methylation_data[binary_samples].T  # Samples as rows\n",
    "y_binary = (pd.Series(binary_labels) == 'HIIT').astype(int).values\n",
    "\n",
    "print(f\"Binary data shape: {X_binary.shape}\")\n",
    "print(f\"Label distribution: HIIT={sum(y_binary)}, Control={len(y_binary)-sum(y_binary)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Statistical Selection at Different Levels\n",
    "\n",
    "We perform feature selection at multiple stringency levels to understand the trade-off between discovery power and stringency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run feature selection at multiple levels\n",
    "levels_to_test = ['L1_discovery', 'L3_standard', 'L5_moderate', 'L7_very_stringent']\n",
    "\n",
    "binary_results = {}\n",
    "for level in levels_to_test:\n",
    "    print(f\"\\nRunning feature selection at {level}...\")\n",
    "    \n",
    "    # Select features at this level\n",
    "    features = selector.select_binary_features(\n",
    "        X_binary,\n",
    "        y_binary,\n",
    "        level=level\n",
    "    )\n",
    "    \n",
    "    binary_results[level] = features\n",
    "    print(f\"  Selected features: {len(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature counts across levels\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "levels = list(binary_results.keys())\n",
    "counts = [len(binary_results[level]) for level in levels]\n",
    "\n",
    "bars = ax.bar(range(len(levels)), counts, color='steelblue', edgecolor='black')\n",
    "ax.set_xticks(range(len(levels)))\n",
    "ax.set_xticklabels([l.replace('_', '\\n') for l in levels], rotation=0)\n",
    "ax.set_ylabel('Number of Selected Features')\n",
    "ax.set_title('Binary Feature Selection: Features at Different Stringency Levels')\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar, count in zip(bars, counts):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, \n",
    "            str(count), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'binary_feature_counts_by_level.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Detailed Statistical Analysis\n",
    "\n",
    "For comprehensive analysis, we examine p-values, effect sizes, and their distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run statistical tests on all probes\n",
    "stat_selector = StatisticalFeatureSelector()\n",
    "\n",
    "# Group samples\n",
    "hiit_samples = [s for s, l in zip(binary_samples, binary_labels) if l == 'HIIT']\n",
    "control_samples = [s for s, l in zip(binary_samples, binary_labels) if l == 'Control']\n",
    "\n",
    "# Calculate statistics for all probes\n",
    "print(\"Calculating statistics for all probes...\")\n",
    "\n",
    "# This would contain the actual implementation\n",
    "# For demonstration, we'll use the selector's internal statistics\n",
    "ttest_results = run_ttest(\n",
    "    methylation_data[hiit_samples],\n",
    "    methylation_data[control_samples]\n",
    ")\n",
    "\n",
    "# Calculate effect sizes (Cohen's d)\n",
    "effect_sizes = calculate_effect_size(\n",
    "    methylation_data[hiit_samples],\n",
    "    methylation_data[control_samples]\n",
    ")\n",
    "\n",
    "# Adjust p-values for multiple testing\n",
    "adjusted_pvalues = adjust_pvalues(ttest_results['pvalue'], method='fdr_bh')\n",
    "\n",
    "print(f\"\\nStatistics calculated for {len(ttest_results)} probes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a statistics DataFrame\n",
    "stats_df = pd.DataFrame({\n",
    "    'probe_id': methylation_data.index,\n",
    "    'pvalue': ttest_results['pvalue'],\n",
    "    'adjusted_pvalue': adjusted_pvalues,\n",
    "    'effect_size': effect_sizes,\n",
    "    't_statistic': ttest_results['statistic']\n",
    "})\n",
    "\n",
    "# Calculate log fold change (difference in means)\n",
    "stats_df['mean_diff'] = (\n",
    "    methylation_data[hiit_samples].mean(axis=1) - \n",
    "    methylation_data[control_samples].mean(axis=1)\n",
    ").values\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Statistical Summary:\")\n",
    "print(f\"  Probes with p < 0.05: {(stats_df['pvalue'] < 0.05).sum():,}\")\n",
    "print(f\"  Probes with adj p < 0.05: {(stats_df['adjusted_pvalue'] < 0.05).sum():,}\")\n",
    "print(f\"  Probes with |effect| > 0.5: {(stats_df['effect_size'].abs() > 0.5).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create volcano plot\n",
    "fig, ax = plot_volcano(\n",
    "    stats_df['mean_diff'],\n",
    "    stats_df['pvalue'],\n",
    "    title='Volcano Plot: HIIT vs Control',\n",
    "    pvalue_threshold=0.05,\n",
    "    effect_threshold=0.1,\n",
    "    figsize=(10, 8)\n",
    ")\n",
    "\n",
    "plt.savefig(figures_dir / 'binary_volcano_plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Machine Learning-Based Selection\n",
    "\n",
    "Complement statistical methods with regularized regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO feature selection\n",
    "print(\"Running LASSO feature selection...\")\n",
    "\n",
    "lasso_selector = LassoFeatureSelector(alpha=0.01)\n",
    "lasso_features = lasso_selector.fit_select(X_binary, y_binary)\n",
    "\n",
    "print(f\"LASSO selected {len(lasso_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net feature selection (combines L1 and L2 regularization)\n",
    "print(\"Running Elastic Net feature selection...\")\n",
    "\n",
    "enet_selector = ElasticNetFeatureSelector(alpha=0.01, l1_ratio=0.5)\n",
    "enet_features = enet_selector.fit_select(X_binary, y_binary)\n",
    "\n",
    "print(f\"Elastic Net selected {len(enet_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest feature importance\n",
    "print(\"Running Random Forest feature selection...\")\n",
    "\n",
    "rf_selector = RandomForestFeatureSelector(\n",
    "    n_estimators=100,\n",
    "    importance_threshold=0.001\n",
    ")\n",
    "rf_features = rf_selector.fit_select(X_binary, y_binary)\n",
    "\n",
    "print(f\"Random Forest selected {len(rf_features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Consensus Features\n",
    "\n",
    "Identify features that are selected by multiple methods for higher confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find consensus features across methods\n",
    "statistical_features = set(binary_results['L5_moderate'])\n",
    "ml_features = set(lasso_features) & set(enet_features) & set(rf_features)\n",
    "\n",
    "# Features selected by both statistical and ML methods\n",
    "consensus_features = statistical_features & ml_features\n",
    "\n",
    "print(\"Consensus Feature Analysis:\")\n",
    "print(f\"  Statistical features (L5): {len(statistical_features)}\")\n",
    "print(f\"  ML consensus features: {len(ml_features)}\")\n",
    "print(f\"  Overall consensus: {len(consensus_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature overlap\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "venn3(\n",
    "    [statistical_features, set(lasso_features), set(rf_features)],\n",
    "    set_labels=('Statistical', 'LASSO', 'Random Forest'),\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Feature Selection Method Overlap (Binary Classification)')\n",
    "\n",
    "plt.savefig(figures_dir / 'binary_feature_overlap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multiclass Feature Selection: HIIT Duration\n",
    "\n",
    "Select features that distinguish between different HIIT training durations (4W, 8W, 12W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare multiclass data\n",
    "X_multi = methylation_data[multiclass_samples].T\n",
    "\n",
    "# Encode labels\n",
    "label_map = {'4W': 0, '8W': 1, '12W': 2}\n",
    "y_multi = np.array([label_map[l] for l in multiclass_labels])\n",
    "\n",
    "print(f\"Multiclass data shape: {X_multi.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y_multi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiclass feature selection\n",
    "multiclass_results = {}\n",
    "\n",
    "for level in ['L1_discovery', 'L3_standard', 'L5_moderate']:\n",
    "    print(f\"\\nRunning multiclass selection at {level}...\")\n",
    "    \n",
    "    features = selector.select_multiclass_features(\n",
    "        X_multi,\n",
    "        y_multi,\n",
    "        level=level\n",
    "    )\n",
    "    \n",
    "    multiclass_results[level] = features\n",
    "    print(f\"  Selected features: {len(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA-based selection for multiclass\n",
    "print(\"\\nRunning ANOVA for multiclass comparison...\")\n",
    "\n",
    "# Group samples by duration\n",
    "groups = {\n",
    "    '4W': [s for s, l in zip(multiclass_samples, multiclass_labels) if l == '4W'],\n",
    "    '8W': [s for s, l in zip(multiclass_samples, multiclass_labels) if l == '8W'],\n",
    "    '12W': [s for s, l in zip(multiclass_samples, multiclass_labels) if l == '12W']\n",
    "}\n",
    "\n",
    "anova_results = run_anova(\n",
    "    [methylation_data[groups['4W']],\n",
    "     methylation_data[groups['8W']],\n",
    "     methylation_data[groups['12W']]]\n",
    ")\n",
    "\n",
    "# Adjust p-values\n",
    "anova_adjusted = adjust_pvalues(anova_results['pvalue'], method='fdr_bh')\n",
    "\n",
    "significant_probes = sum(anova_adjusted < 0.05)\n",
    "print(f\"Significant probes (FDR < 0.05): {significant_probes:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time-Series Feature Analysis\n",
    "\n",
    "Analyze methylation trajectories over the training period to identify CpG sites with consistent temporal patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize time-series analyzer\n",
    "ts_analyzer = TimeSeriesFeatureAnalyzer()\n",
    "\n",
    "# Prepare time-series data\n",
    "# For each individual, we need measurements at multiple timepoints\n",
    "timepoint_map = {'Baseline': 0, '4W HIIT': 4, '8W HIIT': 8, '12W HIIT': 12}\n",
    "\n",
    "# Create time-series structure\n",
    "ts_data = sample_info[\n",
    "    sample_info['time_point'].isin(timepoint_map.keys())\n",
    "].copy()\n",
    "ts_data['time_numeric'] = ts_data['time_point'].map(timepoint_map)\n",
    "\n",
    "print(\"Time-series data structure:\")\n",
    "print(ts_data.groupby('time_point').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal patterns\n",
    "print(\"Analyzing temporal methylation patterns...\")\n",
    "\n",
    "# Run time-series analysis\n",
    "ts_features = ts_analyzer.analyze_trajectories(\n",
    "    methylation_data,\n",
    "    ts_data,\n",
    "    time_column='time_numeric',\n",
    "    individual_column='individual_id'\n",
    ")\n",
    "\n",
    "print(f\"\\nIdentified {len(ts_features)} features with significant temporal patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize temporal patterns\n",
    "# Features can show: increasing, decreasing, or non-monotonic trends\n",
    "\n",
    "if len(ts_features) > 0:\n",
    "    pattern_counts = ts_features['pattern_type'].value_counts()\n",
    "    print(\"Temporal Pattern Distribution:\")\n",
    "    for pattern, count in pattern_counts.items():\n",
    "        print(f\"  {pattern}: {count} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Set Comparison\n",
    "\n",
    "Compare features selected across different tasks and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare binary, multiclass, and time-series features\n",
    "binary_set = set(binary_results['L5_moderate'])\n",
    "multi_set = set(multiclass_results.get('L5_moderate', []))\n",
    "ts_set = set(ts_features['probe_id'].tolist()) if len(ts_features) > 0 else set()\n",
    "\n",
    "print(\"Feature Set Comparison:\")\n",
    "print(f\"  Binary (L5): {len(binary_set)} features\")\n",
    "print(f\"  Multiclass (L5): {len(multi_set)} features\")\n",
    "print(f\"  Time-series: {len(ts_set)} features\")\n",
    "\n",
    "# Calculate overlaps\n",
    "binary_multi = binary_set & multi_set\n",
    "binary_ts = binary_set & ts_set\n",
    "multi_ts = multi_set & ts_set\n",
    "all_three = binary_set & multi_set & ts_set\n",
    "\n",
    "print(f\"\\nOverlaps:\")\n",
    "print(f\"  Binary & Multiclass: {len(binary_multi)}\")\n",
    "print(f\"  Binary & Time-series: {len(binary_ts)}\")\n",
    "print(f\"  Multiclass & Time-series: {len(multi_ts)}\")\n",
    "print(f\"  All three: {len(all_three)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Selected Features\n",
    "\n",
    "Save all feature sets for use in downstream classification and enrichment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save binary features at different levels\n",
    "for level, features in binary_results.items():\n",
    "    feature_path = features_dir / f'binary_features_{level}.csv'\n",
    "    pd.DataFrame({'probe_id': list(features)}).to_csv(feature_path, index=False)\n",
    "    print(f\"Saved: {feature_path.name} ({len(features)} features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save multiclass features\n",
    "for level, features in multiclass_results.items():\n",
    "    feature_path = features_dir / f'multiclass_features_{level}.csv'\n",
    "    pd.DataFrame({'probe_id': list(features)}).to_csv(feature_path, index=False)\n",
    "    print(f\"Saved: {feature_path.name} ({len(features)} features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save consensus features\n",
    "consensus_path = features_dir / 'consensus_features.csv'\n",
    "pd.DataFrame({'probe_id': list(consensus_features)}).to_csv(consensus_path, index=False)\n",
    "print(f\"Saved consensus features: {len(consensus_features)} features\")\n",
    "\n",
    "# Save time-series features\n",
    "if len(ts_features) > 0:\n",
    "    ts_path = features_dir / 'timeseries_features.csv'\n",
    "    ts_features.to_csv(ts_path, index=False)\n",
    "    print(f\"Saved time-series features: {len(ts_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary statistics\n",
    "summary = {\n",
    "    'binary_features': {\n",
    "        level: len(features) for level, features in binary_results.items()\n",
    "    },\n",
    "    'multiclass_features': {\n",
    "        level: len(features) for level, features in multiclass_results.items()\n",
    "    },\n",
    "    'ml_features': {\n",
    "        'lasso': len(lasso_features),\n",
    "        'elastic_net': len(enet_features),\n",
    "        'random_forest': len(rf_features)\n",
    "    },\n",
    "    'consensus_features': len(consensus_features),\n",
    "    'timeseries_features': len(ts_features) if len(ts_features) > 0 else 0\n",
    "}\n",
    "\n",
    "summary_path = features_dir / 'feature_selection_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nSummary saved to: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated the Ten-Level Feature Selection Framework:\n",
    "\n",
    "### Key Accomplishments\n",
    "\n",
    "1. **Framework Configuration**: Set up graduated stringency levels with calibrated thresholds\n",
    "\n",
    "2. **Binary Feature Selection**: Identified CpG sites differentiating HIIT from Control\n",
    "   - Statistical methods (t-test with FDR correction)\n",
    "   - Effect size filtering (Cohen's d)\n",
    "   - Multiple stringency levels for different use cases\n",
    "\n",
    "3. **Multiclass Feature Selection**: Found features distinguishing training durations\n",
    "   - ANOVA-based selection\n",
    "   - Duration-specific patterns\n",
    "\n",
    "4. **Time-Series Analysis**: Identified temporal methylation patterns\n",
    "   - Trajectory analysis across timepoints\n",
    "   - Pattern categorization\n",
    "\n",
    "5. **Consensus Features**: Combined multiple methods for robust selection\n",
    "   - Statistical + ML agreement\n",
    "   - Cross-task overlap analysis\n",
    "\n",
    "### Framework Benefits\n",
    "\n",
    "- **Reproducibility**: Standardized thresholds at each level\n",
    "- **Flexibility**: Choose appropriate stringency for your use case\n",
    "- **Robustness**: Multiple method consensus reduces false discoveries\n",
    "- **Interpretability**: Clear documentation of selection criteria\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Continue to **04_classification.ipynb** to:\n",
    "- Train classifiers using selected features\n",
    "- Evaluate model performance with cross-validation\n",
    "- Compare different feature sets and data versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session summary\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE SELECTION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nBinary features (L5): {len(binary_results['L5_moderate'])}\")\n",
    "print(f\"Multiclass features (L5): {len(multiclass_results.get('L5_moderate', []))}\")\n",
    "print(f\"Consensus features: {len(consensus_features)}\")\n",
    "print(f\"\\nAll feature sets saved to: {features_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
