{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Batch-Aware Model Training and Evaluation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates the classification pipeline for DNA methylation-based prediction of HIIT response. We implement batch-aware training strategies and comprehensive evaluation methods to build robust and reproducible classifiers.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Batch-Aware Classifier**: Models that handle batch effects as covariates\n",
    "2. **Binary Classification**: HIIT intervention vs Control/Baseline\n",
    "3. **Multiclass Classification**: Training duration (4W/8W/12W)\n",
    "4. **Multi-Version Comparison**: Evaluate models across different preprocessing versions\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Configure and train batch-aware classifiers\n",
    "2. Perform stratified cross-validation with proper sample handling\n",
    "3. Evaluate model performance with multiple metrics\n",
    "4. Compare models across different data preprocessing versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Project-specific imports - Classification\n",
    "from src.models import (\n",
    "    ClassifierConfig,\n",
    "    BatchAwareClassifier,\n",
    "    HIITClassificationPipeline,\n",
    "    ModelEvaluator,\n",
    "    CrossValidationStrategy,\n",
    "    MultiVersionComparator\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "from src.visualization import (\n",
    "    plot_roc_curve,\n",
    "    plot_roc_curves,\n",
    "    plot_confusion_matrix,\n",
    "    plot_feature_importance\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define paths\n",
    "processed_dir = project_root / 'data' / 'processed'\n",
    "features_dir = processed_dir / 'features'\n",
    "models_dir = project_root / 'models'\n",
    "figures_dir = project_root / 'data' / 'figures' / 'binary'\n",
    "\n",
    "# Create output directories\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load preprocessed data versions\n",
    "with open(processed_dir / 'methyl_data_versions.pkl', 'rb') as f:\n",
    "    data_versions = pickle.load(f)\n",
    "\n",
    "# Load sample mapping\n",
    "sample_mapping = pd.read_csv(\n",
    "    project_root / 'data' / 'raw' / 'GSE171140_sample_mapping.csv'\n",
    ")\n",
    "\n",
    "print(\"Loaded data versions:\")\n",
    "for name, data in data_versions.items():\n",
    "    print(f\"  {name}: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load selected features\n",
    "binary_features = pd.read_csv(\n",
    "    features_dir / 'binary_features_L5_moderate.csv'\n",
    ")['probe_id'].tolist()\n",
    "\n",
    "multiclass_features = pd.read_csv(\n",
    "    features_dir / 'multiclass_features_L5_moderate.csv'\n",
    ")['probe_id'].tolist()\n",
    "\n",
    "print(f\"Binary features: {len(binary_features)}\")\n",
    "print(f\"Multiclass features: {len(multiclass_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the standardized version for classification\n",
    "methylation_data = data_versions['standardized']\n",
    "\n",
    "# Align samples\n",
    "sample_ids = methylation_data.columns.tolist()\n",
    "sample_info = sample_mapping.set_index('sample_id').loc[sample_ids].reset_index()\n",
    "\n",
    "# Prepare binary classification data\n",
    "binary_mask = sample_info['binary_class'].isin(['HIIT', 'Control'])\n",
    "binary_samples = sample_info[binary_mask]['sample_id'].tolist()\n",
    "binary_labels = (sample_info[binary_mask]['binary_class'] == 'HIIT').astype(int).values\n",
    "\n",
    "# Extract batch information for batch-aware modeling\n",
    "batch_info = sample_info[binary_mask]['study_group'].values\n",
    "\n",
    "print(f\"Binary classification samples: {len(binary_samples)}\")\n",
    "print(f\"  HIIT: {sum(binary_labels)}, Control: {len(binary_labels) - sum(binary_labels)}\")\n",
    "print(f\"  Batches: {np.unique(batch_info)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix for binary classification\n",
    "# Filter to selected features\n",
    "available_features = [f for f in binary_features if f in methylation_data.index]\n",
    "X_binary = methylation_data.loc[available_features, binary_samples].T.values\n",
    "y_binary = binary_labels\n",
    "\n",
    "print(f\"Feature matrix shape: {X_binary.shape}\")\n",
    "print(f\"  Samples: {X_binary.shape[0]}\")\n",
    "print(f\"  Features: {X_binary.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure Classifier\n",
    "\n",
    "The `ClassifierConfig` defines the classifier type and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure classifier\n",
    "config = ClassifierConfig(\n",
    "    classifier_type='random_forest',  # Options: 'logistic', 'svm', 'random_forest', 'xgboost'\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Classifier Configuration:\")\n",
    "print(f\"  Type: {config.classifier_type}\")\n",
    "print(f\"  Parameters: n_estimators={config.n_estimators}, max_depth={config.max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch-Aware Classification\n",
    "\n",
    "The `BatchAwareClassifier` incorporates batch information to reduce confounding effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize batch-aware classifier\n",
    "batch_classifier = BatchAwareClassifier(\n",
    "    config=config,\n",
    "    batch_handling='covariate'  # Options: 'covariate', 'stratified', 'none'\n",
    ")\n",
    "\n",
    "print(\"Batch-Aware Classifier initialized\")\n",
    "print(f\"  Batch handling strategy: {batch_classifier.batch_handling}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier with batch information\n",
    "batch_classifier.fit(X_binary, y_binary, batch=batch_info)\n",
    "\n",
    "# Get training predictions\n",
    "train_predictions = batch_classifier.predict(X_binary)\n",
    "train_probabilities = batch_classifier.predict_proba(X_binary)[:, 1]\n",
    "\n",
    "print(\"\\nTraining Performance:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_binary, train_predictions):.3f}\")\n",
    "print(f\"  AUC-ROC: {roc_auc_score(y_binary, train_probabilities):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation Evaluation\n",
    "\n",
    "We use stratified cross-validation to obtain unbiased performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure cross-validation strategy\n",
    "cv_strategy = CrossValidationStrategy(\n",
    "    n_splits=5,\n",
    "    n_repeats=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Cross-Validation Configuration:\")\n",
    "print(f\"  Folds: {cv_strategy.n_splits}\")\n",
    "print(f\"  Repeats: {cv_strategy.n_repeats}\")\n",
    "print(f\"  Total iterations: {cv_strategy.n_splits * cv_strategy.n_repeats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation\n",
    "print(\"\\nRunning cross-validation...\")\n",
    "\n",
    "cv_results = cv_strategy.evaluate(\n",
    "    batch_classifier,\n",
    "    X_binary,\n",
    "    y_binary,\n",
    "    batch=batch_info\n",
    ")\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"  Accuracy: {cv_results['accuracy_mean']:.3f} +/- {cv_results['accuracy_std']:.3f}\")\n",
    "print(f\"  AUC-ROC: {cv_results['auc_mean']:.3f} +/- {cv_results['auc_std']:.3f}\")\n",
    "print(f\"  F1 Score: {cv_results['f1_mean']:.3f} +/- {cv_results['f1_std']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cross-validation performance distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics = ['accuracy', 'auc', 'f1']\n",
    "titles = ['Accuracy', 'AUC-ROC', 'F1 Score']\n",
    "\n",
    "for ax, metric, title in zip(axes, metrics, titles):\n",
    "    values = cv_results[f'{metric}_scores']\n",
    "    ax.hist(values, bins=20, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(x=np.mean(values), color='red', linestyle='--', \n",
    "               label=f'Mean: {np.mean(values):.3f}')\n",
    "    ax.set_xlabel(title)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'{title} Distribution')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'cv_performance_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation with ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model evaluator\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "# Get detailed evaluation metrics\n",
    "eval_results = evaluator.evaluate(\n",
    "    batch_classifier,\n",
    "    X_binary,\n",
    "    y_binary\n",
    ")\n",
    "\n",
    "print(\"Detailed Evaluation Metrics:\")\n",
    "for metric, value in eval_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "fig, ax = plot_roc_curve(\n",
    "    y_binary,\n",
    "    train_probabilities,\n",
    "    title='ROC Curve: HIIT vs Control Classification',\n",
    "    figsize=(8, 8)\n",
    ")\n",
    "\n",
    "plt.savefig(figures_dir / 'roc_curve_binary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    y_binary,\n",
    "    train_predictions,\n",
    "    class_names=['Control', 'HIIT'],\n",
    "    title='Confusion Matrix: HIIT vs Control',\n",
    "    figsize=(8, 6)\n",
    ")\n",
    "\n",
    "plt.savefig(figures_dir / 'confusion_matrix_binary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the trained model\n",
    "importances = batch_classifier.get_feature_importance()\n",
    "\n",
    "# Create importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': available_features,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "fig, ax = plot_feature_importance(\n",
    "    importance_df.head(20)['feature'].tolist(),\n",
    "    importance_df.head(20)['importance'].tolist(),\n",
    "    title='Top 20 Feature Importances',\n",
    "    figsize=(10, 8)\n",
    ")\n",
    "\n",
    "plt.savefig(figures_dir / 'feature_importance_top20.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Multi-Version Model Comparison\n",
    "\n",
    "Compare classifier performance across different preprocessing versions to assess robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize multi-version comparator\n",
    "comparator = MultiVersionComparator(\n",
    "    classifier_config=config,\n",
    "    cv_strategy=cv_strategy\n",
    ")\n",
    "\n",
    "print(\"Multi-Version Comparator initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare across data versions\n",
    "print(\"Comparing across data versions...\")\n",
    "\n",
    "version_results = {}\n",
    "for version_name, version_data in data_versions.items():\n",
    "    print(f\"\\nEvaluating: {version_name}\")\n",
    "    \n",
    "    # Extract features for this version\n",
    "    available = [f for f in binary_features if f in version_data.index]\n",
    "    X_version = version_data.loc[available, binary_samples].T.values\n",
    "    \n",
    "    # Run cross-validation\n",
    "    results = comparator.evaluate_version(\n",
    "        X_version,\n",
    "        y_binary,\n",
    "        batch=batch_info\n",
    "    )\n",
    "    \n",
    "    version_results[version_name] = results\n",
    "    print(f\"  AUC: {results['auc_mean']:.3f} +/- {results['auc_std']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize version comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "versions = list(version_results.keys())\n",
    "means = [version_results[v]['auc_mean'] for v in versions]\n",
    "stds = [version_results[v]['auc_std'] for v in versions]\n",
    "\n",
    "bars = ax.bar(range(len(versions)), means, yerr=stds, \n",
    "              color='steelblue', edgecolor='black', capsize=5)\n",
    "ax.set_xticks(range(len(versions)))\n",
    "ax.set_xticklabels([v.replace('_', '\\n') for v in versions])\n",
    "ax.set_ylabel('AUC-ROC')\n",
    "ax.set_title('Classification Performance Across Data Versions')\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "\n",
    "# Add value labels\n",
    "for bar, mean in zip(bars, means):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "            f'{mean:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'version_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Multiclass Classification: HIIT Duration\n",
    "\n",
    "Train a classifier to distinguish between 4W, 8W, and 12W training durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare multiclass data\n",
    "multi_mask = sample_info['multi_class'].notna()\n",
    "multi_samples = sample_info[multi_mask]['sample_id'].tolist()\n",
    "multi_labels_str = sample_info[multi_mask]['multi_class'].values\n",
    "multi_batch = sample_info[multi_mask]['study_group'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = {'4W': 0, '8W': 1, '12W': 2}\n",
    "multi_labels = np.array([label_encoder[l] for l in multi_labels_str])\n",
    "\n",
    "# Extract feature matrix\n",
    "available_multi = [f for f in multiclass_features if f in methylation_data.index]\n",
    "X_multi = methylation_data.loc[available_multi, multi_samples].T.values\n",
    "\n",
    "print(f\"Multiclass classification:\")\n",
    "print(f\"  Samples: {X_multi.shape[0]}\")\n",
    "print(f\"  Features: {X_multi.shape[1]}\")\n",
    "print(f\"  Class distribution: {np.bincount(multi_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiclass classifier\n",
    "multi_config = ClassifierConfig(\n",
    "    classifier_type='random_forest',\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "multi_classifier = BatchAwareClassifier(\n",
    "    config=multi_config,\n",
    "    batch_handling='covariate'\n",
    ")\n",
    "\n",
    "# Fit and evaluate\n",
    "multi_classifier.fit(X_multi, multi_labels, batch=multi_batch)\n",
    "multi_predictions = multi_classifier.predict(X_multi)\n",
    "\n",
    "print(\"\\nMulticlass Training Performance:\")\n",
    "print(f\"  Accuracy: {accuracy_score(multi_labels, multi_predictions):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for multiclass\n",
    "multi_cv_results = cv_strategy.evaluate(\n",
    "    multi_classifier,\n",
    "    X_multi,\n",
    "    multi_labels,\n",
    "    batch=multi_batch\n",
    ")\n",
    "\n",
    "print(\"\\nMulticlass Cross-Validation Results:\")\n",
    "print(f\"  Accuracy: {multi_cv_results['accuracy_mean']:.3f} +/- {multi_cv_results['accuracy_std']:.3f}\")\n",
    "print(f\"  F1 (macro): {multi_cv_results['f1_mean']:.3f} +/- {multi_cv_results['f1_std']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass confusion matrix\n",
    "multiclass_figures_dir = project_root / 'data' / 'figures' / 'multiclass'\n",
    "multiclass_figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    multi_labels,\n",
    "    multi_predictions,\n",
    "    class_names=['4W', '8W', '12W'],\n",
    "    title='Confusion Matrix: HIIT Duration Classification',\n",
    "    figsize=(8, 6)\n",
    ")\n",
    "\n",
    "plt.savefig(multiclass_figures_dir / 'confusion_matrix_multiclass.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. HIIT Classification Pipeline\n",
    "\n",
    "The `HIITClassificationPipeline` provides a complete end-to-end workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the complete pipeline\n",
    "pipeline = HIITClassificationPipeline(\n",
    "    classifier_config=config,\n",
    "    cv_strategy=cv_strategy,\n",
    "    output_dir=str(models_dir)\n",
    ")\n",
    "\n",
    "print(\"HIIT Classification Pipeline initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete pipeline\n",
    "pipeline_results = pipeline.run(\n",
    "    X_binary,\n",
    "    y_binary,\n",
    "    batch=batch_info,\n",
    "    feature_names=available_features\n",
    ")\n",
    "\n",
    "print(\"\\nPipeline Results:\")\n",
    "print(f\"  Best Model AUC: {pipeline_results['best_auc']:.3f}\")\n",
    "print(f\"  Model saved to: {pipeline_results['model_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save binary classifier\n",
    "binary_model_path = models_dir / 'binary_classifier.pkl'\n",
    "with open(binary_model_path, 'wb') as f:\n",
    "    pickle.dump(batch_classifier, f)\n",
    "print(f\"Binary classifier saved: {binary_model_path}\")\n",
    "\n",
    "# Save multiclass classifier\n",
    "multi_model_path = models_dir / 'multiclass_classifier.pkl'\n",
    "with open(multi_model_path, 'wb') as f:\n",
    "    pickle.dump(multi_classifier, f)\n",
    "print(f\"Multiclass classifier saved: {multi_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation results\n",
    "results_summary = {\n",
    "    'binary_classification': {\n",
    "        'accuracy': cv_results['accuracy_mean'],\n",
    "        'accuracy_std': cv_results['accuracy_std'],\n",
    "        'auc': cv_results['auc_mean'],\n",
    "        'auc_std': cv_results['auc_std'],\n",
    "        'f1': cv_results['f1_mean'],\n",
    "        'f1_std': cv_results['f1_std']\n",
    "    },\n",
    "    'multiclass_classification': {\n",
    "        'accuracy': multi_cv_results['accuracy_mean'],\n",
    "        'accuracy_std': multi_cv_results['accuracy_std'],\n",
    "        'f1': multi_cv_results['f1_mean'],\n",
    "        'f1_std': multi_cv_results['f1_std']\n",
    "    },\n",
    "    'version_comparison': {\n",
    "        v: {'auc_mean': r['auc_mean'], 'auc_std': r['auc_std']}\n",
    "        for v, r in version_results.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "results_path = models_dir / 'classification_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"Results saved: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we completed the classification pipeline:\n",
    "\n",
    "### Key Accomplishments\n",
    "\n",
    "1. **Binary Classification**: HIIT vs Control\n",
    "   - Batch-aware Random Forest classifier\n",
    "   - Cross-validated performance metrics\n",
    "   - ROC curve and confusion matrix analysis\n",
    "\n",
    "2. **Multiclass Classification**: 4W/8W/12W duration\n",
    "   - Trained duration classifier\n",
    "   - Evaluated with stratified cross-validation\n",
    "\n",
    "3. **Multi-Version Comparison**\n",
    "   - Compared performance across preprocessing versions\n",
    "   - Identified most robust preprocessing approach\n",
    "\n",
    "4. **Feature Importance**\n",
    "   - Ranked features by predictive importance\n",
    "   - Identified top biomarker candidates\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Continue to **05_enrichment_analysis.ipynb** to:\n",
    "- Map CpG features to genes\n",
    "- Perform GO and KEGG pathway enrichment\n",
    "- Understand biological significance of identified biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session summary\n",
    "print(\"=\" * 60)\n",
    "print(\"CLASSIFICATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nBinary Classification (HIIT vs Control):\")\n",
    "print(f\"  CV Accuracy: {cv_results['accuracy_mean']:.3f}\")\n",
    "print(f\"  CV AUC-ROC: {cv_results['auc_mean']:.3f}\")\n",
    "print(f\"\\nMulticlass Classification (Duration):\")\n",
    "print(f\"  CV Accuracy: {multi_cv_results['accuracy_mean']:.3f}\")\n",
    "print(f\"\\nModels saved to: {models_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
