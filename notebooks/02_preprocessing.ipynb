{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates the preprocessing pipeline for DNA methylation data, preparing it for feature selection and classification. Proper preprocessing is critical for obtaining reliable and reproducible results in methylation-based biomarker discovery.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Assess data quality and identify issues\n",
    "2. Filter low-variance CpG probes\n",
    "3. Handle missing values appropriately\n",
    "4. Detect and correct batch effects\n",
    "5. Create multiple preprocessing versions for robust analysis\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This notebook assumes you have completed **01_data_acquisition.ipynb** and have:\n",
    "- Downloaded the GSE171140 series matrix file\n",
    "- Created the sample mapping file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Project-specific imports\n",
    "from src.data.loader import GEODataLoader\n",
    "from src.data.preprocessing import (\n",
    "    MethylationPreprocessor,\n",
    "    normalize_beta_values,\n",
    "    calculate_missing_rate\n",
    ")\n",
    "from src.visualization import (\n",
    "    plot_pca_visualization,\n",
    "    plot_heatmap\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_dir = project_root / 'data' / 'raw'\n",
    "processed_dir = project_root / 'data' / 'processed'\n",
    "figures_dir = project_root / 'data' / 'figures' / 'qc'\n",
    "\n",
    "# Create output directories\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load methylation data\n",
    "loader = GEODataLoader('GSE171140', data_dir=data_dir)\n",
    "methylation_data = loader.load_methylation_matrix()\n",
    "\n",
    "# Load sample mapping\n",
    "sample_mapping = pd.read_csv(data_dir / 'GSE171140_sample_mapping.csv')\n",
    "\n",
    "print(f\"Methylation data shape: {methylation_data.shape}\")\n",
    "print(f\"Sample mapping shape: {sample_mapping.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Data Quality Assessment\n",
    "\n",
    "Before preprocessing, we need to understand the quality characteristics of our data:\n",
    "\n",
    "- **Beta value range**: Should be [0, 1]\n",
    "- **Missing value patterns**: How many and where?\n",
    "- **Variance distribution**: Identify uninformative probes\n",
    "- **Sample-to-sample correlations**: Identify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data quality statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Beta value range check\n",
    "print(f\"\\nBeta Value Range:\")\n",
    "print(f\"  Minimum: {methylation_data.min().min():.6f}\")\n",
    "print(f\"  Maximum: {methylation_data.max().max():.6f}\")\n",
    "print(f\"  Mean: {methylation_data.mean().mean():.6f}\")\n",
    "\n",
    "# Missing value assessment\n",
    "total_missing = methylation_data.isna().sum().sum()\n",
    "total_values = methylation_data.size\n",
    "missing_pct = (total_missing / total_values) * 100\n",
    "\n",
    "print(f\"\\nMissing Values:\")\n",
    "print(f\"  Total missing: {total_missing:,}\")\n",
    "print(f\"  Total values: {total_values:,}\")\n",
    "print(f\"  Missing percentage: {missing_pct:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probe-level statistics\n",
    "probe_missing_rate = calculate_missing_rate(methylation_data, axis=1)\n",
    "probe_variance = methylation_data.var(axis=1)\n",
    "\n",
    "print(\"\\nProbe-level Statistics:\")\n",
    "print(f\"  Probes with any missing: {(probe_missing_rate > 0).sum():,}\")\n",
    "print(f\"  Probes with >10% missing: {(probe_missing_rate > 0.1).sum():,}\")\n",
    "print(f\"  Probes with >20% missing: {(probe_missing_rate > 0.2).sum():,}\")\n",
    "\n",
    "print(f\"\\nVariance Statistics:\")\n",
    "print(f\"  Min variance: {probe_variance.min():.6f}\")\n",
    "print(f\"  Max variance: {probe_variance.max():.6f}\")\n",
    "print(f\"  Median variance: {probe_variance.median():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize probe variance distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Variance histogram\n",
    "axes[0].hist(probe_variance, bins=100, edgecolor='none', alpha=0.7)\n",
    "axes[0].axvline(x=0.02, color='red', linestyle='--', label='Threshold (0.02)')\n",
    "axes[0].set_xlabel('Probe Variance')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Probe Variance')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlim(0, 0.1)\n",
    "\n",
    "# Missing rate histogram\n",
    "axes[1].hist(probe_missing_rate[probe_missing_rate > 0], bins=50, edgecolor='none', alpha=0.7)\n",
    "axes[1].axvline(x=0.2, color='red', linestyle='--', label='Threshold (20%)')\n",
    "axes[1].set_xlabel('Missing Rate per Probe')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Missing Rates')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'qc_probe_statistics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalize Beta Values\n",
    "\n",
    "Ensure all beta values are within the valid range [0, 1]. Values outside this range can occur due to technical artifacts and should be clipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize beta values to valid range\n",
    "methylation_normalized = normalize_beta_values(\n",
    "    methylation_data,\n",
    "    clip_range=(0.0, 1.0)\n",
    ")\n",
    "\n",
    "print(\"After normalization:\")\n",
    "print(f\"  Min: {methylation_normalized.min().min():.6f}\")\n",
    "print(f\"  Max: {methylation_normalized.max().max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize the Preprocessor\n",
    "\n",
    "The `MethylationPreprocessor` class provides a unified interface for all preprocessing operations with configurable thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor with configurable thresholds\n",
    "# std_threshold: probes with std < threshold are removed\n",
    "# missing_threshold: probes with missing rate > threshold are removed\n",
    "\n",
    "preprocessor = MethylationPreprocessor(\n",
    "    std_threshold=0.02,      # Remove probes with std < 0.02\n",
    "    missing_threshold=0.2    # Remove probes with >20% missing\n",
    ")\n",
    "\n",
    "print(\"Preprocessor configuration:\")\n",
    "print(f\"  Standard deviation threshold: {preprocessor.std_threshold}\")\n",
    "print(f\"  Missing value threshold: {preprocessor.missing_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Filter Low-Variance Probes\n",
    "\n",
    "CpG sites with low variance across samples provide little discriminative information and can increase noise. We remove probes below a minimum variance threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter low variance probes\n",
    "print(f\"\\nOriginal probe count: {methylation_normalized.shape[0]:,}\")\n",
    "\n",
    "filtered_data, probe_stats = preprocessor.filter_low_variance(\n",
    "    methylation_normalized,\n",
    "    threshold=0.02,\n",
    "    return_stats=True\n",
    ")\n",
    "\n",
    "n_removed = methylation_normalized.shape[0] - filtered_data.shape[0]\n",
    "pct_removed = (n_removed / methylation_normalized.shape[0]) * 100\n",
    "\n",
    "print(f\"\\nAfter variance filtering:\")\n",
    "print(f\"  Remaining probes: {filtered_data.shape[0]:,}\")\n",
    "print(f\"  Removed probes: {n_removed:,} ({pct_removed:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize probe statistics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Mean vs Std plot\n",
    "sample_idx = np.random.choice(len(probe_stats), min(10000, len(probe_stats)), replace=False)\n",
    "axes[0].scatter(\n",
    "    probe_stats.iloc[sample_idx]['mean'],\n",
    "    probe_stats.iloc[sample_idx]['std'],\n",
    "    alpha=0.3, s=1\n",
    ")\n",
    "axes[0].axhline(y=0.02, color='red', linestyle='--', label='Variance threshold')\n",
    "axes[0].set_xlabel('Mean Beta Value')\n",
    "axes[0].set_ylabel('Standard Deviation')\n",
    "axes[0].set_title('Mean-Variance Relationship')\n",
    "axes[0].legend()\n",
    "\n",
    "# Retained vs removed comparison\n",
    "retained_mask = probe_stats['std'] >= 0.02\n",
    "axes[1].hist(probe_stats.loc[~retained_mask, 'std'], bins=50, alpha=0.5, label='Removed', color='red')\n",
    "axes[1].hist(probe_stats.loc[retained_mask, 'std'], bins=50, alpha=0.5, label='Retained', color='green')\n",
    "axes[1].set_xlabel('Standard Deviation')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Variance Distribution by Filtering Status')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'qc_variance_filtering.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Handle Missing Values\n",
    "\n",
    "Missing values in methylation data can occur due to detection failures or quality filtering. We use a two-step approach:\n",
    "\n",
    "1. **Remove probes with high missing rates** (>20%)\n",
    "2. **Impute remaining missing values** using probe median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values after variance filtering\n",
    "missing_before = filtered_data.isna().sum().sum()\n",
    "print(f\"Missing values before imputation: {missing_before:,}\")\n",
    "\n",
    "# Handle missing values\n",
    "imputed_data = preprocessor.handle_missing_values(\n",
    "    filtered_data,\n",
    "    strategy='median',  # Options: 'median', 'mean', 'knn', 'drop'\n",
    "    drop_threshold=0.2\n",
    ")\n",
    "\n",
    "missing_after = imputed_data.isna().sum().sum()\n",
    "print(f\"Missing values after imputation: {missing_after}\")\n",
    "print(f\"\\nFinal probe count: {imputed_data.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Effect Detection\n",
    "\n",
    "Batch effects are systematic technical variations that can confound biological signals. We detect potential batch effects by:\n",
    "\n",
    "1. Examining PCA plots colored by study group\n",
    "2. Analyzing sample correlations within and between batches\n",
    "3. Testing for significant differences between batch groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch information from sample mapping\n",
    "# In this study, 'study_group' can indicate different batches\n",
    "sample_ids = imputed_data.columns.tolist()\n",
    "batch_info = sample_mapping.set_index('sample_id').loc[sample_ids, 'study_group']\n",
    "\n",
    "print(\"Batch distribution:\")\n",
    "print(batch_info.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization to detect batch effects\n",
    "# Transpose data: samples as rows, probes as columns\n",
    "data_for_pca = imputed_data.T\n",
    "\n",
    "# Create sample labels for coloring\n",
    "sample_labels = batch_info.values\n",
    "\n",
    "# Perform PCA visualization\n",
    "fig, ax, pca_result = plot_pca_visualization(\n",
    "    data_for_pca,\n",
    "    sample_labels,\n",
    "    title='PCA of Methylation Data by Study Group',\n",
    "    figsize=(10, 8)\n",
    ")\n",
    "\n",
    "plt.savefig(figures_dir / 'pca_batch_effect.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPCA variance explained:\")\n",
    "print(f\"  PC1: {pca_result.explained_variance_ratio_[0]*100:.1f}%\")\n",
    "print(f\"  PC2: {pca_result.explained_variance_ratio_[1]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color by timepoint to compare with batch structure\n",
    "timepoint_labels = sample_mapping.set_index('sample_id').loc[sample_ids, 'time_point'].values\n",
    "\n",
    "fig, ax, _ = plot_pca_visualization(\n",
    "    data_for_pca,\n",
    "    timepoint_labels,\n",
    "    title='PCA of Methylation Data by Timepoint',\n",
    "    figsize=(10, 8)\n",
    ")\n",
    "\n",
    "plt.savefig(figures_dir / 'pca_timepoint.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Batch Effect Correction (Optional)\n",
    "\n",
    "If significant batch effects are detected, we can apply correction methods. The preprocessor supports:\n",
    "\n",
    "- **Median centering**: Simple approach that centers each batch to the global median\n",
    "- **ComBat**: Empirical Bayes method (requires pycombat package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply batch correction if needed\n",
    "# Uncomment if batch effects are significant in your analysis\n",
    "\n",
    "# batch_corrected = preprocessor.apply_batch_correction(\n",
    "#     imputed_data,\n",
    "#     batch_info,\n",
    "#     method='median_centering'  # Options: 'median_centering', 'combat'\n",
    "# )\n",
    "\n",
    "# For this example, we'll continue without batch correction\n",
    "# The decision depends on the magnitude of batch effects relative to biological signal\n",
    "\n",
    "print(\"Batch correction: Not applied (optional step)\")\n",
    "print(\"Evaluate PCA plots to determine if correction is needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Multiple Data Versions\n",
    "\n",
    "For robust analysis, we create multiple versions of the preprocessed data:\n",
    "\n",
    "1. **Original**: Filtered and imputed data\n",
    "2. **Standardized**: Z-score normalized per probe\n",
    "3. **Batch-corrected**: With median centering (if applicable)\n",
    "\n",
    "Different versions may perform better for different classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple data versions\n",
    "data_versions = preprocessor.create_data_versions(\n",
    "    imputed_data,\n",
    "    batch_info=batch_info\n",
    ")\n",
    "\n",
    "print(\"Created data versions:\")\n",
    "for version_name, version_data in data_versions.items():\n",
    "    print(f\"  {version_name}: {version_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare data distributions across versions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "for ax, (version_name, version_data) in zip(axes.flat, data_versions.items()):\n",
    "    # Sample a subset for visualization\n",
    "    sample_values = version_data.values.flatten()\n",
    "    sample_values = sample_values[~np.isnan(sample_values)]\n",
    "    sample_values = np.random.choice(sample_values, min(100000, len(sample_values)), replace=False)\n",
    "    \n",
    "    ax.hist(sample_values, bins=100, edgecolor='none', alpha=0.7)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'{version_name.replace(\"_\", \" \").title()}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'data_version_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sample Quality Control\n",
    "\n",
    "Identify potential outlier samples that may need exclusion from downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sample-level statistics\n",
    "sample_stats = pd.DataFrame({\n",
    "    'sample_id': imputed_data.columns,\n",
    "    'mean': imputed_data.mean(axis=0),\n",
    "    'std': imputed_data.std(axis=0),\n",
    "    'median': imputed_data.median(axis=0)\n",
    "})\n",
    "\n",
    "# Add sample information\n",
    "sample_stats = sample_stats.merge(\n",
    "    sample_mapping[['sample_id', 'time_point', 'binary_class']],\n",
    "    on='sample_id'\n",
    ")\n",
    "\n",
    "print(\"Sample statistics summary:\")\n",
    "print(sample_stats[['mean', 'std', 'median']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify potential outliers using IQR method\n",
    "Q1 = sample_stats['mean'].quantile(0.25)\n",
    "Q3 = sample_stats['mean'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = sample_stats[\n",
    "    (sample_stats['mean'] < lower_bound) | \n",
    "    (sample_stats['mean'] > upper_bound)\n",
    "]\n",
    "\n",
    "print(f\"\\nPotential outlier samples: {len(outliers)}\")\n",
    "if len(outliers) > 0:\n",
    "    print(outliers[['sample_id', 'mean', 'time_point']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample statistics by group\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Boxplot of mean by timepoint\n",
    "sample_stats.boxplot(column='mean', by='time_point', ax=axes[0])\n",
    "axes[0].set_xlabel('Timepoint')\n",
    "axes[0].set_ylabel('Mean Beta Value')\n",
    "axes[0].set_title('Sample Mean by Timepoint')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Mean vs Std scatter\n",
    "for group in sample_stats['binary_class'].unique():\n",
    "    mask = sample_stats['binary_class'] == group\n",
    "    axes[1].scatter(\n",
    "        sample_stats.loc[mask, 'mean'],\n",
    "        sample_stats.loc[mask, 'std'],\n",
    "        label=group, alpha=0.7\n",
    "    )\n",
    "axes[1].set_xlabel('Mean Beta Value')\n",
    "axes[1].set_ylabel('Standard Deviation')\n",
    "axes[1].set_title('Sample Mean vs Std by Class')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'sample_qc.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Preprocessed Data\n",
    "\n",
    "Save all preprocessed data versions for use in feature selection and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "# Save the primary preprocessed data\n",
    "preprocessed_path = processed_dir / 'methyl_data_preprocessed.pkl'\n",
    "with open(preprocessed_path, 'wb') as f:\n",
    "    pickle.dump(imputed_data, f)\n",
    "\n",
    "print(f\"Preprocessed data saved to: {preprocessed_path}\")\n",
    "\n",
    "# Save all versions\n",
    "versions_path = processed_dir / 'methyl_data_versions.pkl'\n",
    "with open(versions_path, 'wb') as f:\n",
    "    pickle.dump(data_versions, f)\n",
    "\n",
    "print(f\"All data versions saved to: {versions_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessing configuration for reproducibility\n",
    "preprocessing_config = {\n",
    "    'std_threshold': preprocessor.std_threshold,\n",
    "    'missing_threshold': preprocessor.missing_threshold,\n",
    "    'original_probes': methylation_data.shape[0],\n",
    "    'filtered_probes': imputed_data.shape[0],\n",
    "    'n_samples': imputed_data.shape[1],\n",
    "    'data_versions': list(data_versions.keys())\n",
    "}\n",
    "\n",
    "config_path = processed_dir / 'preprocessing_config.json'\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(preprocessing_config, f, indent=2)\n",
    "\n",
    "print(f\"Configuration saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we completed the following preprocessing steps:\n",
    "\n",
    "1. **Quality Assessment**: Evaluated raw data for missing values and variance distribution\n",
    "2. **Beta Value Normalization**: Clipped values to [0, 1] range\n",
    "3. **Variance Filtering**: Removed low-variance probes\n",
    "4. **Missing Value Imputation**: Handled missing data using median imputation\n",
    "5. **Batch Effect Detection**: Visualized potential batch effects using PCA\n",
    "6. **Multi-Version Creation**: Created original, standardized, and batch-corrected versions\n",
    "7. **Sample QC**: Identified potential outlier samples\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Continue to **03_feature_selection.ipynb** to:\n",
    "- Apply the Ten-Level Feature Selection Framework\n",
    "- Select binary classification features (HIIT vs Control)\n",
    "- Select multiclass classification features (4W/8W/12W)\n",
    "- Analyze time-series features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session summary\n",
    "print(\"=\" * 60)\n",
    "print(\"PREPROCESSING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nOriginal probes: {methylation_data.shape[0]:,}\")\n",
    "print(f\"Final probes: {imputed_data.shape[0]:,}\")\n",
    "print(f\"Reduction: {(1 - imputed_data.shape[0]/methylation_data.shape[0])*100:.1f}%\")\n",
    "print(f\"\\nSamples: {imputed_data.shape[1]}\")\n",
    "print(f\"Data versions created: {len(data_versions)}\")\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  - {preprocessed_path}\")\n",
    "print(f\"  - {versions_path}\")\n",
    "print(f\"  - {config_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
